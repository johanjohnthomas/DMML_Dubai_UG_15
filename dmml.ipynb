{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9719332,"sourceType":"datasetVersion","datasetId":5946338}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-21T00:04:43.029457Z","iopub.execute_input":"2024-11-21T00:04:43.029882Z","iopub.status.idle":"2024-11-21T00:04:43.038516Z","shell.execute_reply.started":"2024-11-21T00:04:43.029844Z","shell.execute_reply":"2024-11-21T00:04:43.037325Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/forest-fires-regression/forestfires.csv\n","output_type":"stream"}],"execution_count":49},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler, OneHotEncoder, LabelEncoder, KBinsDiscretizer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import (\n    accuracy_score,\n    confusion_matrix,\n    precision_score,\n    recall_score,\n    roc_auc_score,\n    classification_report,\n    mean_absolute_error, \n    mean_squared_error\n)\nfrom sklearn.svm import SVR\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.pipeline import Pipeline\nimport matplotlib.pyplot as plt\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T00:07:04.298886Z","iopub.execute_input":"2024-11-21T00:07:04.299334Z","iopub.status.idle":"2024-11-21T00:07:04.307796Z","shell.execute_reply.started":"2024-11-21T00:07:04.299288Z","shell.execute_reply":"2024-11-21T00:07:04.306315Z"}},"outputs":[],"execution_count":82},{"cell_type":"markdown","source":"# Forest Fire data representation","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/forest-fires-regression/forestfires.csv\")\ndf.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T00:07:05.241412Z","iopub.execute_input":"2024-11-21T00:07:05.241856Z","iopub.status.idle":"2024-11-21T00:07:05.283153Z","shell.execute_reply.started":"2024-11-21T00:07:05.241822Z","shell.execute_reply":"2024-11-21T00:07:05.281829Z"}},"outputs":[{"execution_count":83,"output_type":"execute_result","data":{"text/plain":"                X           Y        FFMC         DMC          DC         ISI  \\\ncount  517.000000  517.000000  517.000000  517.000000  517.000000  517.000000   \nmean     4.669246    4.299807   90.644681  110.872340  547.940039    9.021663   \nstd      2.313778    1.229900    5.520111   64.046482  248.066192    4.559477   \nmin      1.000000    2.000000   18.700000    1.100000    7.900000    0.000000   \n25%      3.000000    4.000000   90.200000   68.600000  437.700000    6.500000   \n50%      4.000000    4.000000   91.600000  108.300000  664.200000    8.400000   \n75%      7.000000    5.000000   92.900000  142.400000  713.900000   10.800000   \nmax      9.000000    9.000000   96.200000  291.300000  860.600000   56.100000   \n\n             temp          RH        wind        rain         area  \ncount  517.000000  517.000000  517.000000  517.000000   517.000000  \nmean    18.889168   44.288201    4.017602    0.021663    12.847292  \nstd      5.806625   16.317469    1.791653    0.295959    63.655818  \nmin      2.200000   15.000000    0.400000    0.000000     0.000000  \n25%     15.500000   33.000000    2.700000    0.000000     0.000000  \n50%     19.300000   42.000000    4.000000    0.000000     0.520000  \n75%     22.800000   53.000000    4.900000    0.000000     6.570000  \nmax     33.300000  100.000000    9.400000    6.400000  1090.840000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X</th>\n      <th>Y</th>\n      <th>FFMC</th>\n      <th>DMC</th>\n      <th>DC</th>\n      <th>ISI</th>\n      <th>temp</th>\n      <th>RH</th>\n      <th>wind</th>\n      <th>rain</th>\n      <th>area</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>517.000000</td>\n      <td>517.000000</td>\n      <td>517.000000</td>\n      <td>517.000000</td>\n      <td>517.000000</td>\n      <td>517.000000</td>\n      <td>517.000000</td>\n      <td>517.000000</td>\n      <td>517.000000</td>\n      <td>517.000000</td>\n      <td>517.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>4.669246</td>\n      <td>4.299807</td>\n      <td>90.644681</td>\n      <td>110.872340</td>\n      <td>547.940039</td>\n      <td>9.021663</td>\n      <td>18.889168</td>\n      <td>44.288201</td>\n      <td>4.017602</td>\n      <td>0.021663</td>\n      <td>12.847292</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>2.313778</td>\n      <td>1.229900</td>\n      <td>5.520111</td>\n      <td>64.046482</td>\n      <td>248.066192</td>\n      <td>4.559477</td>\n      <td>5.806625</td>\n      <td>16.317469</td>\n      <td>1.791653</td>\n      <td>0.295959</td>\n      <td>63.655818</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>18.700000</td>\n      <td>1.100000</td>\n      <td>7.900000</td>\n      <td>0.000000</td>\n      <td>2.200000</td>\n      <td>15.000000</td>\n      <td>0.400000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>3.000000</td>\n      <td>4.000000</td>\n      <td>90.200000</td>\n      <td>68.600000</td>\n      <td>437.700000</td>\n      <td>6.500000</td>\n      <td>15.500000</td>\n      <td>33.000000</td>\n      <td>2.700000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>91.600000</td>\n      <td>108.300000</td>\n      <td>664.200000</td>\n      <td>8.400000</td>\n      <td>19.300000</td>\n      <td>42.000000</td>\n      <td>4.000000</td>\n      <td>0.000000</td>\n      <td>0.520000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>7.000000</td>\n      <td>5.000000</td>\n      <td>92.900000</td>\n      <td>142.400000</td>\n      <td>713.900000</td>\n      <td>10.800000</td>\n      <td>22.800000</td>\n      <td>53.000000</td>\n      <td>4.900000</td>\n      <td>0.000000</td>\n      <td>6.570000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>9.000000</td>\n      <td>9.000000</td>\n      <td>96.200000</td>\n      <td>291.300000</td>\n      <td>860.600000</td>\n      <td>56.100000</td>\n      <td>33.300000</td>\n      <td>100.000000</td>\n      <td>9.400000</td>\n      <td>6.400000</td>\n      <td>1090.840000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":83},{"cell_type":"markdown","source":"# Implementing diff models and algorithms","metadata":{}},{"cell_type":"markdown","source":"## Helper functions & Data Preprocessing","metadata":{}},{"cell_type":"code","source":"def evaluate_model(model_name, y_test, y_pred):\n    mad = mean_absolute_error(y_test, y_pred)\n    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n    print(f\"{model_name} Performance:\")\n    print(f\"Mean Absolute Deviation (MAD): {mad}\")\n    print(f\"Root Mean Squared Error (RMSE): {rmse}\\n\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T00:07:06.642016Z","iopub.execute_input":"2024-11-21T00:07:06.642418Z","iopub.status.idle":"2024-11-21T00:07:06.648077Z","shell.execute_reply.started":"2024-11-21T00:07:06.642384Z","shell.execute_reply":"2024-11-21T00:07:06.646959Z"}},"outputs":[],"execution_count":84},{"cell_type":"code","source":"\nnumerical_features = ['temp', 'RH', 'wind', 'rain']  \ncategorical_features = []  \n# Preprocess the data\ndef preprocess_data(df, target, categorical_features, numerical_features):\n    # Log-transform the target variable\n    y = np.log1p(df[target])  \n    \n    # Remove the target column from the features\n    X = df.drop(columns=[target])\n    \n    # Define transformers\n    preprocess = ColumnTransformer(\n        transformers=[\n            ('num', StandardScaler(), numerical_features),\n            ('cat', OneHotEncoder(), categorical_features)\n        ]\n    )\n    \n    # Apply transformations\n    X_transformed = preprocess.fit_transform(X)\n    \n    # Split the dataset into train and test sets\n    return train_test_split(X_transformed, y, test_size=0.2, random_state=42)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T00:07:07.204422Z","iopub.execute_input":"2024-11-21T00:07:07.204853Z","iopub.status.idle":"2024-11-21T00:07:07.211763Z","shell.execute_reply.started":"2024-11-21T00:07:07.204816Z","shell.execute_reply":"2024-11-21T00:07:07.210574Z"}},"outputs":[],"execution_count":85},{"cell_type":"markdown","source":"### Neural network","metadata":{}},{"cell_type":"code","source":"def neural_network(X_train, X_test, y_train, y_test):\n    model = MLPRegressor(hidden_layer_sizes=(10,), max_iter=1000, solver='adam',learning_rate_init=0.001,early_stopping=True, random_state=42)\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    evaluate_model(\"Neural Network\", y_test, y_pred)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T00:07:07.957216Z","iopub.execute_input":"2024-11-21T00:07:07.957630Z","iopub.status.idle":"2024-11-21T00:07:07.963541Z","shell.execute_reply.started":"2024-11-21T00:07:07.957596Z","shell.execute_reply":"2024-11-21T00:07:07.962433Z"}},"outputs":[],"execution_count":86},{"cell_type":"markdown","source":"### Optimimzing MLP","metadata":{}},{"cell_type":"code","source":"# Cross-Validation for MLP\ndef cross_validate_mlp(X, y):\n    model = MLPRegressor(hidden_layer_sizes=(10,), max_iter=500, solver='adam', learning_rate_init=0.001, random_state=42)\n    scorer = make_scorer(mean_squared_error, squared=False)\n    scores = cross_val_score(model, X, y, cv=5, scoring=scorer)\n    print(\"Cross-validated RMSE scores:\", scores)\n    print(\"Mean RMSE:\", scores.mean())\n\n# Hyperparameter Tuning for MLP\ndef tune_mlp(X_train, y_train):\n    param_grid = {\n        'hidden_layer_sizes': [(10,), (50,), (100,)],\n        'learning_rate_init': [0.001, 0.01, 0.1],\n        'solver': ['adam', 'sgd'],\n        'max_iter': [500, 1000]\n    }\n    \n    model = MLPRegressor(random_state=42, early_stopping=True)\n    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n    grid_search.fit(X_train, y_train)\n    \n    best_model = grid_search.best_estimator_\n    print(\"Best Parameters:\", grid_search.best_params_)\n    print(\"Best RMSE:\", np.sqrt(-grid_search.best_score_))\n    return best_model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T00:07:08.621657Z","iopub.execute_input":"2024-11-21T00:07:08.622065Z","iopub.status.idle":"2024-11-21T00:07:08.630618Z","shell.execute_reply.started":"2024-11-21T00:07:08.622029Z","shell.execute_reply":"2024-11-21T00:07:08.629349Z"}},"outputs":[],"execution_count":87},{"cell_type":"markdown","source":"### Evaluate","metadata":{}},{"cell_type":"code","source":"# Define target and features\ntarget_column = 'area'\nnumerical_features = ['temp', 'RH', 'wind', 'rain']\ncategorical_features = []  # Add categorical features if needed\n\n# Preprocess data\nX_train, X_test, y_train, y_test = preprocess_data(df, target_column, categorical_features, numerical_features)\n\n# Cross-validate MLP\nprint(\"Cross-Validation Results for MLP:\")\ncross_validate_mlp(X_train, y_train)\n\n# Hyperparameter tuning for MLP\nprint(\"\\nHyperparameter Tuning for MLP:\")\nbest_mlp = tune_mlp(X_train, y_train)\n\n# Evaluate best MLP on the test set\ny_pred = best_mlp.predict(X_test)\nevaluate_model(\"Tuned MLP Regressor\", y_test, y_pred)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T00:07:09.235810Z","iopub.execute_input":"2024-11-21T00:07:09.236230Z","iopub.status.idle":"2024-11-21T00:07:16.866847Z","shell.execute_reply.started":"2024-11-21T00:07:09.236193Z","shell.execute_reply":"2024-11-21T00:07:16.864671Z"}},"outputs":[{"name":"stdout","text":"Cross-Validation Results for MLP:\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Cross-validated RMSE scores: [1.41556921 1.26431999 1.70147067 1.54545318 1.26838491]\nMean RMSE: 1.4390395931493056\n\nHyperparameter Tuning for MLP:\nBest Parameters: {'hidden_layer_sizes': (50,), 'learning_rate_init': 0.001, 'max_iter': 500, 'solver': 'sgd'}\nBest RMSE: 1.3859581187939796\nTuned MLP Regressor Performance:\nMean Absolute Deviation (MAD): 1.1573045980401029\nRoot Mean Squared Error (RMSE): 1.453821275015725\n\n","output_type":"stream"}],"execution_count":88},{"cell_type":"markdown","source":"## SVM\n","metadata":{}},{"cell_type":"code","source":"def support_vector_machine(X_train, X_test, y_train, y_test):\n    model = SVR(kernel='rbf', C=3, epsilon=0.1, gamma='scale')\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    evaluate_model(\"Support Vector Machine\", y_test, y_pred)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T00:07:16.869479Z","iopub.execute_input":"2024-11-21T00:07:16.870078Z","iopub.status.idle":"2024-11-21T00:07:16.882360Z","shell.execute_reply.started":"2024-11-21T00:07:16.870013Z","shell.execute_reply":"2024-11-21T00:07:16.880506Z"}},"outputs":[],"execution_count":89},{"cell_type":"markdown","source":"### Optimizing SVM","metadata":{}},{"cell_type":"code","source":"# Cross-validate SVM\ndef cross_validate_svm(X, y):\n    model = SVR(kernel='rbf', C=3, epsilon=0.1, gamma='scale')\n    scorer = make_scorer(mean_squared_error, squared=False)  # Use RMSE\n    scores = cross_val_score(model, X, y, cv=5, scoring=scorer)\n    \n    # Print cross-validation scores\n    print(\"Cross-Validation Results for SVM:\")\n    for i, score in enumerate(scores, 1):\n        print(f\"Fold {i}: RMSE = {score:.4f}\")\n    print(f\"Mean RMSE: {np.mean(scores):.4f}\")\n    print(f\"Standard Deviation of RMSE: {np.std(scores):.4f}\\n\")\n\n# Hyperparameter tuning for SVM\ndef tune_svm(X_train, y_train):\n    param_grid = {\n        'C': [0.1, 1, 10, 100],\n        'epsilon': [0.01, 0.1, 0.5, 1],\n        'gamma': ['scale', 'auto', 0.01, 0.1]\n    }\n    model = SVR(kernel='rbf')\n    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n    grid_search.fit(X_train, y_train)\n    \n    # Extract best parameters and results\n    best_model = grid_search.best_estimator_\n    best_params = grid_search.best_params_\n    best_score = np.sqrt(-grid_search.best_score_)  # Convert negative MSE to RMSE\n    \n    print(\"Hyperparameter Tuning Results for SVM:\")\n    print(f\"Best Parameters: {best_params}\")\n    print(f\"Best RMSE: {best_score:.4f}\\n\")\n    \n    return best_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T00:07:16.900658Z","iopub.execute_input":"2024-11-21T00:07:16.901333Z","iopub.status.idle":"2024-11-21T00:07:16.929130Z","shell.execute_reply.started":"2024-11-21T00:07:16.901232Z","shell.execute_reply":"2024-11-21T00:07:16.927294Z"}},"outputs":[],"execution_count":90},{"cell_type":"markdown","source":"### Evaluation","metadata":{}},{"cell_type":"code","source":"# Evaluate SVM\nprint(\"Cross-Validation Results for SVM:\")\ncross_validate_svm(X_train, y_train)\n\nprint(\"\\nHyperparameter Tuning for SVM:\")\nbest_svm = tune_svm(X_train, y_train)\n\n# Evaluate best SVM on the test set\ny_pred = best_svm.predict(X_test)\nevaluate_model(\"Tuned Support Vector Machine\", y_test, y_pred)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T00:07:17.783121Z","iopub.execute_input":"2024-11-21T00:07:17.783545Z","iopub.status.idle":"2024-11-21T00:07:19.948333Z","shell.execute_reply.started":"2024-11-21T00:07:17.783508Z","shell.execute_reply":"2024-11-21T00:07:19.947139Z"}},"outputs":[{"name":"stdout","text":"Cross-Validation Results for SVM:\nCross-Validation Results for SVM:\nFold 1: RMSE = 1.4865\nFold 2: RMSE = 1.4091\nFold 3: RMSE = 1.6665\nFold 4: RMSE = 1.6731\nFold 5: RMSE = 1.2988\nMean RMSE: 1.5068\nStandard Deviation of RMSE: 0.1458\n\n\nHyperparameter Tuning for SVM:\nHyperparameter Tuning Results for SVM:\nBest Parameters: {'C': 100, 'epsilon': 1, 'gamma': 0.01}\nBest RMSE: 1.3699\n\nTuned Support Vector Machine Performance:\nMean Absolute Deviation (MAD): 1.1675611358607194\nRoot Mean Squared Error (RMSE): 1.4712687197338465\n\n","output_type":"stream"}],"execution_count":91},{"cell_type":"markdown","source":"## Naive Bayes Algorithms\n### Change the areas into diff. classes","metadata":{}},{"cell_type":"code","source":"# Define the classification function\ndef classify_area(area):\n    if area == 0:\n        return 0  # No fire\n    elif area <= 5:\n        return 1  # Small fire\n    elif area <= 20:\n        return 2  # Medium fire\n    else:\n        return 3  # Large fire\n\n# Apply the function to create a new column\ndf['area_class'] = df['area'].apply(classify_area)\n\n# Check the class distribution\nprint(\"Class distribution for 'area_class':\")\nprint(df['area_class'].value_counts())# Define the classification function\ndef classify_area(area):\n    if area == 0:\n        return 0  # No fire\n    elif area <= 5:\n        return 1  # Small fire\n    elif area <= 20:\n        return 2  # Medium fire\n    else:\n        return 3  # Large fire\n\n# Apply the function to create a new column\ndf['area_class'] = df['area'].apply(classify_area)\n\n# Check the class distribution\nprint(\"Class distribution for 'area_class':\")\nprint(df['area_class'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T00:07:19.949955Z","iopub.execute_input":"2024-11-21T00:07:19.950319Z","iopub.status.idle":"2024-11-21T00:07:19.962893Z","shell.execute_reply.started":"2024-11-21T00:07:19.950284Z","shell.execute_reply":"2024-11-21T00:07:19.961438Z"}},"outputs":[{"name":"stdout","text":"Class distribution for 'area_class':\narea_class\n0    247\n1    119\n2     92\n3     59\nName: count, dtype: int64\nClass distribution for 'area_class':\narea_class\n0    247\n1    119\n2     92\n3     59\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":92},{"cell_type":"markdown","source":"### pre-process the data","metadata":{}},{"cell_type":"code","source":"def preprocess_classification_data(df, target, categorical_features, numerical_features):\n    # Encode target labels\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(df[target])  # Converts target labels to integers\n\n    # Define preprocessing for features\n    preprocess = ColumnTransformer(\n        transformers=[\n            (\"cat\", OneHotEncoder(), categorical_features),  # One-hot encode categorical features\n            (\"num\", MinMaxScaler(), numerical_features),  # Min-max scale numerical features\n        ]\n    )\n\n    # Apply transformations to input features\n    X = preprocess.fit_transform(df.drop(columns=[target]))\n\n    # Split data into training and testing sets\n    return train_test_split(X, y, test_size=0.3, random_state=42), label_encoder","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T00:07:49.766348Z","iopub.execute_input":"2024-11-21T00:07:49.766727Z","iopub.status.idle":"2024-11-21T00:07:49.773925Z","shell.execute_reply.started":"2024-11-21T00:07:49.766692Z","shell.execute_reply":"2024-11-21T00:07:49.772256Z"}},"outputs":[],"execution_count":100},{"cell_type":"markdown","source":"## Multinomial Bayes\n","metadata":{}},{"cell_type":"code","source":"# Cross-validation function\ndef cross_validate_multinomial_nb(X, y):\n    model = MultinomialNB()\n    scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n    \n    print(\"Cross-Validation Results for Multinomial Naive Bayes:\")\n    print(f\"Accuracy Scores: {scores}\")\n    print(f\"Mean Accuracy: {scores.mean():.4f}\")\n    print(f\"Standard Deviation: {scores.std():.4f}\")\n    print(\"-\" * 50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T00:07:50.771307Z","iopub.execute_input":"2024-11-21T00:07:50.771706Z","iopub.status.idle":"2024-11-21T00:07:50.777562Z","shell.execute_reply.started":"2024-11-21T00:07:50.771669Z","shell.execute_reply":"2024-11-21T00:07:50.776384Z"}},"outputs":[],"execution_count":101},{"cell_type":"code","source":"# Hyperparameter tuning using Grid Search\ndef grid_search_multinomial_nb(X_train, y_train):\n    param_grid = {\n        'alpha': [0.1, 0.5, 1.0, 2.0, 5.0]  # Laplace smoothing parameter\n    }\n    model = MultinomialNB()\n    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n    grid_search.fit(X_train, y_train)\n    \n    print(\"Grid Search Results for Multinomial Naive Bayes:\")\n    print(f\"Best Parameters: {grid_search.best_params_}\")\n    print(f\"Best Cross-Validation Accuracy: {grid_search.best_score_:.4f}\")\n    print(\"-\" * 50)\n    return grid_search.best_estimator_","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T00:07:52.250621Z","iopub.execute_input":"2024-11-21T00:07:52.251026Z","iopub.status.idle":"2024-11-21T00:07:52.257957Z","shell.execute_reply.started":"2024-11-21T00:07:52.250992Z","shell.execute_reply":"2024-11-21T00:07:52.256471Z"}},"outputs":[],"execution_count":102},{"cell_type":"code","source":"def calculate_specificity(y_true, y_pred):\n    cm = confusion_matrix(y_true, y_pred)\n    tn = cm[0, 0]  # True Negatives\n    fp = cm[0, 1]  # False Positives\n    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n    return specificity\ndef multinomial_nb(X_train, X_test, y_train, y_test):\n    # Cross-validation\n    cross_validate_multinomial_nb(X_train, y_train)\n\n    # Grid search\n    best_model = grid_search_multinomial_nb(X_train, y_train)\n\n    # Train the best model on the training set\n    best_model.fit(X_train, y_train)\n    \n    # Make predictions\n    y_pred = best_model.predict(X_test)\n    y_proba = best_model.predict_proba(X_test)[:, 1] if len(best_model.classes_) == 2 else None\n\n    # Metrics\n    accuracy = accuracy_score(y_test, y_pred)\n    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n    recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n    cm = confusion_matrix(y_test, y_pred)\n    specificity = calculate_specificity(y_test, y_pred)\n    auc = roc_auc_score(y_test, y_proba) if y_proba is not None else \"Not applicable for multiclass\"\n\n    # Print Metrics\n    print(\"Final Evaluation with Tuned Multinomial Naive Bayes:\")\n    print(f\"Accuracy: {accuracy:.4f}\")\n    print(f\"Precision: {precision:.4f}\")\n    print(f\"Recall (Sensitivity): {recall:.4f}\")\n    print(f\"Specificity: {specificity:.4f}\")\n    if y_proba is not None:\n        print(f\"AUC: {auc:.4f}\")\n    print(\"Confusion Matrix:\")\n    print(cm)\n    print(\"-\" * 50)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T00:07:52.811290Z","iopub.execute_input":"2024-11-21T00:07:52.811756Z","iopub.status.idle":"2024-11-21T00:07:52.822795Z","shell.execute_reply.started":"2024-11-21T00:07:52.811668Z","shell.execute_reply":"2024-11-21T00:07:52.821441Z"}},"outputs":[],"execution_count":103},{"cell_type":"markdown","source":"# With area","metadata":{}},{"cell_type":"code","source":"# Define target and features\ntarget_column = 'area'  # Burned area column\ncategorical_features = []  # Replace with categorical feature names if available\nnumerical_features = ['temp', 'RH', 'wind', 'rain']  # Numerical feature names from dataset\n\n# Preprocess the dataset\n(train_X, test_X, train_y, test_y), label_encoder = preprocess_classification_data(\n    df, target_column, categorical_features, numerical_features\n)\n\n# Train and evaluate Multinomial Naive Bayes\nmultinomial_nb(train_X, test_X, train_y, test_y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T00:07:54.074040Z","iopub.execute_input":"2024-11-21T00:07:54.074462Z","iopub.status.idle":"2024-11-21T00:07:54.166308Z","shell.execute_reply.started":"2024-11-21T00:07:54.074425Z","shell.execute_reply":"2024-11-21T00:07:54.165179Z"}},"outputs":[{"name":"stdout","text":"Cross-Validation Results for Multinomial Naive Bayes:\nAccuracy Scores: [0.46575342 0.47222222 0.47222222 0.47222222 0.47222222]\nMean Accuracy: 0.4709\nStandard Deviation: 0.0026\n--------------------------------------------------\nGrid Search Results for Multinomial Naive Bayes:\nBest Parameters: {'alpha': 0.1}\nBest Cross-Validation Accuracy: 0.4709\n--------------------------------------------------\nFinal Evaluation with Tuned Multinomial Naive Bayes:\nAccuracy: 0.4936\nPrecision: 0.2436\nRecall (Sensitivity): 0.4936\nSpecificity: 1.0000\nConfusion Matrix:\n[[77  0  0 ...  0  0  0]\n [ 1  0  0 ...  0  0  0]\n [ 1  0  0 ...  0  0  0]\n ...\n [ 1  0  0 ...  0  0  0]\n [ 1  0  0 ...  0  0  0]\n [ 1  0  0 ...  0  0  0]]\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":104},{"cell_type":"markdown","source":"# With class 0 evaluating with area class","metadata":{}},{"cell_type":"code","source":"# Define target and features\ntarget_column = 'area_class'  # New target column\ncategorical_features = []  # Replace with categorical feature names\nnumerical_features = ['temp', 'RH', 'wind', 'rain']  # Numerical feature names\n\n\n# Preprocess the dataset\n(train_X, test_X, train_y, test_y), label_encoder = preprocess_classification_data(\n    df, target_column, categorical_features, numerical_features\n)\n\n# Train and evaluate Multinomial Naive Bayes\nmultinomial_nb(train_X, test_X, train_y, test_y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T00:07:55.351231Z","iopub.execute_input":"2024-11-21T00:07:55.351640Z","iopub.status.idle":"2024-11-21T00:07:55.425851Z","shell.execute_reply.started":"2024-11-21T00:07:55.351606Z","shell.execute_reply":"2024-11-21T00:07:55.424632Z"}},"outputs":[{"name":"stdout","text":"Cross-Validation Results for Multinomial Naive Bayes:\nAccuracy Scores: [0.46575342 0.47222222 0.47222222 0.47222222 0.47222222]\nMean Accuracy: 0.4709\nStandard Deviation: 0.0026\n--------------------------------------------------\nGrid Search Results for Multinomial Naive Bayes:\nBest Parameters: {'alpha': 0.1}\nBest Cross-Validation Accuracy: 0.4709\n--------------------------------------------------\nFinal Evaluation with Tuned Multinomial Naive Bayes:\nAccuracy: 0.4936\nPrecision: 0.2436\nRecall (Sensitivity): 0.4936\nSpecificity: 1.0000\nConfusion Matrix:\n[[77  0  0  0]\n [34  0  0  0]\n [27  0  0  0]\n [18  0  0  0]]\n--------------------------------------------------\n","output_type":"stream"}],"execution_count":105},{"cell_type":"markdown","source":"# Without class 0","metadata":{}},{"cell_type":"code","source":"# Remove rows where area_class == 0\ndf_filtered = df[df['area_class'] != 0]\n\n# Update target column to 'area_class'\ntarget_column = 'area_class'\n\n# Preprocess and train\n(train_X, test_X, train_y, test_y), label_encoder = preprocess_classification_data(\n    df_filtered, target_column, categorical_features, numerical_features\n)\nmultinomial_nb(train_X, test_X, train_y, test_y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T00:08:17.751686Z","iopub.execute_input":"2024-11-21T00:08:17.752085Z","iopub.status.idle":"2024-11-21T00:08:17.827194Z","shell.execute_reply.started":"2024-11-21T00:08:17.752049Z","shell.execute_reply":"2024-11-21T00:08:17.825884Z"}},"outputs":[{"name":"stdout","text":"Cross-Validation Results for Multinomial Naive Bayes:\nAccuracy Scores: [0.42105263 0.39473684 0.39473684 0.39473684 0.40540541]\nMean Accuracy: 0.4021\nStandard Deviation: 0.0103\n--------------------------------------------------\nGrid Search Results for Multinomial Naive Bayes:\nBest Parameters: {'alpha': 2.0}\nBest Cross-Validation Accuracy: 0.4075\n--------------------------------------------------\nFinal Evaluation with Tuned Multinomial Naive Bayes:\nAccuracy: 0.5185\nPrecision: 0.2689\nRecall (Sensitivity): 0.5185\nSpecificity: 1.0000\nConfusion Matrix:\n[[42  0  0]\n [24  0  0]\n [15  0  0]]\n--------------------------------------------------\n","output_type":"stream"}],"execution_count":108},{"cell_type":"markdown","source":"## Gaussian Naive Bayes","metadata":{}},{"cell_type":"code","source":"# Cross-validation for GaussianNB\ndef cross_validate_gaussian_nb(X, y):\n    model = GaussianNB()\n    scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n    \n    print(\"Cross-Validation Results for Gaussian Naive Bayes:\")\n    print(f\"Accuracy Scores: {scores}\")\n    print(f\"Mean Accuracy: {scores.mean():.4f}\")\n    print(f\"Standard Deviation: {scores.std():.4f}\")\n    print(\"-\" * 50)\n\n# Hyperparameter tuning for GaussianNB (tuning var_smoothing)\ndef grid_search_gaussian_nb(X_train, y_train):\n    param_grid = {\n        'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5]  # Example range for variance smoothing\n    }\n    model = GaussianNB()\n    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n    grid_search.fit(X_train, y_train)\n    \n    print(\"Grid Search Results for Gaussian Naive Bayes:\")\n    print(f\"Best Parameters: {grid_search.best_params_}\")\n    print(f\"Best Cross-Validation Accuracy: {grid_search.best_score_:.4f}\")\n    print(\"-\" * 50)\n    return grid_search.best_estimator_","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T00:08:24.315760Z","iopub.execute_input":"2024-11-21T00:08:24.316171Z","iopub.status.idle":"2024-11-21T00:08:24.324016Z","shell.execute_reply.started":"2024-11-21T00:08:24.316138Z","shell.execute_reply":"2024-11-21T00:08:24.322819Z"}},"outputs":[],"execution_count":109},{"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\n# Train and evaluate GaussianNB with cross-validation and grid search\ndef gaussian_nb(X_train, X_test, y_train, y_test):\n    # Cross-validation\n    cross_validate_gaussian_nb(X_train, y_train)\n\n    # Grid search\n    best_model = grid_search_gaussian_nb(X_train, y_train)\n\n    # Train the best model on the training set\n    best_model.fit(X_train, y_train)\n    \n    # Make predictions\n    y_pred = best_model.predict(X_test)\n    y_proba = best_model.predict_proba(X_test)[:, 1] if len(best_model.classes_) == 2 else None\n\n    # Evaluate performance\n    accuracy = accuracy_score(y_test, y_pred)\n    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n    recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n    cm = confusion_matrix(y_test, y_pred)\n    specificity = calculate_specificity(y_test, y_pred)\n    auc = roc_auc_score(y_test, y_proba) if y_proba is not None else \"Not applicable for multiclass\"\n\n    # Print Metrics\n    print(\"Final Evaluation with Tuned Gaussian Naive Bayes:\")\n    print(f\"Accuracy: {accuracy:.4f}\")\n    print(f\"Precision: {precision:.4f}\")\n    print(f\"Recall (Sensitivity): {recall:.4f}\")\n    print(f\"Specificity: {specificity:.4f}\")\n    if y_proba is not None:\n        print(f\"AUC: {auc:.4f}\")\n    print(\"Confusion Matrix:\")\n    print(cm)\n    print(\"-\" * 50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T00:09:30.093456Z","iopub.execute_input":"2024-11-21T00:09:30.093975Z","iopub.status.idle":"2024-11-21T00:09:30.105321Z","shell.execute_reply.started":"2024-11-21T00:09:30.093911Z","shell.execute_reply":"2024-11-21T00:09:30.103052Z"}},"outputs":[],"execution_count":112},{"cell_type":"markdown","source":"# Area","metadata":{}},{"cell_type":"code","source":"# Define target and features\ntarget_column = 'area'\ncategorical_features = []  # Replace with categorical feature names if available\nnumerical_features = ['temp', 'RH', 'wind', 'rain']  # Numerical features\n\n# Preprocess and train\n(train_X, test_X, train_y, test_y), label_encoder = preprocess_classification_data(\n    df, target_column, categorical_features, numerical_features\n)\ngaussian_nb(train_X, test_X, train_y, test_y)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T00:09:31.061643Z","iopub.execute_input":"2024-11-21T00:09:31.062507Z","iopub.status.idle":"2024-11-21T00:09:31.385343Z","shell.execute_reply.started":"2024-11-21T00:09:31.062463Z","shell.execute_reply":"2024-11-21T00:09:31.384350Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Cross-Validation Results for Gaussian Naive Bayes:\nAccuracy Scores: [0.01369863 0.04166667 0.01388889 0.375      0.27777778]\nMean Accuracy: 0.1444\nStandard Deviation: 0.1521\n--------------------------------------------------\nGrid Search Results for Gaussian Naive Bayes:\nBest Parameters: {'var_smoothing': 1e-05}\nBest Cross-Validation Accuracy: 0.3491\n--------------------------------------------------\nFinal Evaluation with Tuned Gaussian Naive Bayes:\nAccuracy: 0.2821\nPrecision: 0.2088\nRecall (Sensitivity): 0.2821\nSpecificity: 0.8800\nConfusion Matrix:\n[[44  6  0 ...  0  0  0]\n [ 0  0  0 ...  0  0  0]\n [ 1  0  0 ...  0  0  0]\n ...\n [ 1  0  0 ...  0  0  0]\n [ 1  0  0 ...  0  0  0]\n [ 1  0  0 ...  0  0  0]]\n--------------------------------------------------\n","output_type":"stream"}],"execution_count":113},{"cell_type":"markdown","source":"# with area class","metadata":{}},{"cell_type":"code","source":"# Update target column to 'area_class'\ntarget_column = 'area_class'\n\n# Preprocess and train\n(train_X, test_X, train_y, test_y), label_encoder = preprocess_classification_data(\n    df, target_column, categorical_features, numerical_features\n)\ngaussian_nb(train_X, test_X, train_y, test_y)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T00:09:33.396955Z","iopub.execute_input":"2024-11-21T00:09:33.397617Z","iopub.status.idle":"2024-11-21T00:09:33.485663Z","shell.execute_reply.started":"2024-11-21T00:09:33.397566Z","shell.execute_reply":"2024-11-21T00:09:33.484357Z"}},"outputs":[{"name":"stdout","text":"Cross-Validation Results for Gaussian Naive Bayes:\nAccuracy Scores: [0.21917808 0.23611111 0.25       0.19444444 0.23611111]\nMean Accuracy: 0.2272\nStandard Deviation: 0.0191\n--------------------------------------------------\nGrid Search Results for Gaussian Naive Bayes:\nBest Parameters: {'var_smoothing': 1e-09}\nBest Cross-Validation Accuracy: 0.2272\n--------------------------------------------------\nFinal Evaluation with Tuned Gaussian Naive Bayes:\nAccuracy: 0.2179\nPrecision: 0.5419\nRecall (Sensitivity): 0.2179\nSpecificity: 0.0137\nConfusion Matrix:\n[[ 1 72  1  3]\n [ 0 33  1  0]\n [ 0 26  0  1]\n [ 0 18  0  0]]\n--------------------------------------------------\n","output_type":"stream"}],"execution_count":114},{"cell_type":"markdown","source":"# With area class excluding class 0","metadata":{}},{"cell_type":"code","source":"# Remove rows where area_class == 0\ndf_filtered = df[df['area_class'] != 0]\n\n# Update target column to 'area_class'\ntarget_column = 'area_class'\n\n# Preprocess and train\n(train_X, test_X, train_y, test_y), label_encoder = preprocess_classification_data(\n    df_filtered, target_column, categorical_features, numerical_features\n)\ngaussian_nb(train_X, test_X, train_y, test_y)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T00:09:34.662985Z","iopub.execute_input":"2024-11-21T00:09:34.664090Z","iopub.status.idle":"2024-11-21T00:09:34.739852Z","shell.execute_reply.started":"2024-11-21T00:09:34.664036Z","shell.execute_reply":"2024-11-21T00:09:34.738600Z"}},"outputs":[{"name":"stdout","text":"Cross-Validation Results for Gaussian Naive Bayes:\nAccuracy Scores: [0.23684211 0.23684211 0.31578947 0.23684211 0.2972973 ]\nMean Accuracy: 0.2647\nStandard Deviation: 0.0346\n--------------------------------------------------\nGrid Search Results for Gaussian Naive Bayes:\nBest Parameters: {'var_smoothing': 1e-09}\nBest Cross-Validation Accuracy: 0.2647\n--------------------------------------------------\nFinal Evaluation with Tuned Gaussian Naive Bayes:\nAccuracy: 0.1852\nPrecision: 0.0343\nRecall (Sensitivity): 0.1852\nSpecificity: 0.0000\nConfusion Matrix:\n[[ 0  0 42]\n [ 0  0 24]\n [ 0  0 15]]\n--------------------------------------------------\n","output_type":"stream"}],"execution_count":115},{"cell_type":"markdown","source":"## Categorical Naive Bayes","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import KBinsDiscretizer\n\ndef preprocess_for_categorical_nb(df, target, numerical_features, n_bins=5):\n    \"\"\"\n    Preprocess data for CategoricalNB by discretizing numerical features.\n    \"\"\"\n    # Encode the target as integers\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(df[target])\n    \n    # Discretize numerical features\n    discretizer = KBinsDiscretizer(n_bins=n_bins, encode='ordinal', strategy='uniform')\n    X_discretized = discretizer.fit_transform(df[numerical_features])\n\n    # Return transformed features, target, and discretizer\n    return train_test_split(X_discretized, y, test_size=0.3, random_state=42), label_encoder\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T00:09:35.910326Z","iopub.execute_input":"2024-11-21T00:09:35.911199Z","iopub.status.idle":"2024-11-21T00:09:35.918111Z","shell.execute_reply.started":"2024-11-21T00:09:35.911153Z","shell.execute_reply":"2024-11-21T00:09:35.916728Z"}},"outputs":[],"execution_count":116},{"cell_type":"code","source":"from sklearn.naive_bayes import CategoricalNB\n\n# Cross-validation for CategoricalNB\ndef cross_validate_categorical_nb(X, y):\n    model = CategoricalNB()\n    scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n    \n    print(\"Cross-Validation Results for Categorical Naive Bayes:\")\n    print(f\"Accuracy Scores: {scores}\")\n    print(f\"Mean Accuracy: {scores.mean():.4f}\")\n    print(f\"Standard Deviation: {scores.std():.4f}\")\n    print(\"-\" * 50)\n\n# Hyperparameter tuning for CategoricalNB\ndef grid_search_categorical_nb(X_train, y_train):\n    param_grid = {\n        'alpha': [0.1, 0.5, 1.0, 2.0, 5.0]  # Laplace smoothing parameter\n    }\n    model = CategoricalNB()\n    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n    grid_search.fit(X_train, y_train)\n    \n    print(\"Grid Search Results for Categorical Naive Bayes:\")\n    print(f\"Best Parameters: {grid_search.best_params_}\")\n    print(f\"Best Cross-Validation Accuracy: {grid_search.best_score_:.4f}\")\n    print(\"-\" * 50)\n    return grid_search.best_estimator_","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T00:09:36.742813Z","iopub.execute_input":"2024-11-21T00:09:36.743197Z","iopub.status.idle":"2024-11-21T00:09:36.751673Z","shell.execute_reply.started":"2024-11-21T00:09:36.743162Z","shell.execute_reply":"2024-11-21T00:09:36.750225Z"}},"outputs":[],"execution_count":117},{"cell_type":"code","source":"# Train and evaluate CategoricalNB\ndef categorical_nb(X_train, X_test, y_train, y_test):\n    # Initialize and train the model\n    model = CategoricalNB()\n    model.fit(X_train, y_train)\n    \n    # Make predictions\n    y_pred = model.predict(X_test)\n\n    # Evaluate performance\n    accuracy = accuracy_score(y_test, y_pred)\n    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n    recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n    cm = confusion_matrix(y_test, y_pred)\n\n    # Print Metrics\n    print(\"Categorical Naive Bayes Performance:\")\n    print(f\"Accuracy: {accuracy:.4f}\")\n    print(f\"Precision: {precision:.4f}\")\n    print(f\"Recall: {recall:.4f}\")\n    print(\"Confusion Matrix:\")\n    print(cm)\n    print(\"-\" * 50)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T00:09:37.271436Z","iopub.execute_input":"2024-11-21T00:09:37.272122Z","iopub.status.idle":"2024-11-21T00:09:37.280470Z","shell.execute_reply.started":"2024-11-21T00:09:37.272065Z","shell.execute_reply":"2024-11-21T00:09:37.278962Z"}},"outputs":[],"execution_count":118},{"cell_type":"markdown","source":"# With Area","metadata":{}},{"cell_type":"code","source":"# Define target and features\ntarget_column = 'area'\ncategorical_features = []  # Replace with categorical feature names if available\nnumerical_features = ['temp', 'RH', 'wind', 'rain']  # Numerical features\n\n# Preprocess and train\n(train_X, test_X, train_y, test_y), label_encoder = preprocess_classification_data(\n    df, target_column, categorical_features, numerical_features\n)\ncategorical_nb(train_X, test_X, train_y, test_y)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T00:09:38.435894Z","iopub.execute_input":"2024-11-21T00:09:38.436328Z","iopub.status.idle":"2024-11-21T00:09:38.466944Z","shell.execute_reply.started":"2024-11-21T00:09:38.436291Z","shell.execute_reply":"2024-11-21T00:09:38.465806Z"}},"outputs":[{"name":"stdout","text":"Categorical Naive Bayes Performance:\nAccuracy: 0.4936\nPrecision: 0.2436\nRecall: 0.4936\nConfusion Matrix:\n[[77  0  0 ...  0  0  0]\n [ 1  0  0 ...  0  0  0]\n [ 1  0  0 ...  0  0  0]\n ...\n [ 1  0  0 ...  0  0  0]\n [ 1  0  0 ...  0  0  0]\n [ 1  0  0 ...  0  0  0]]\n--------------------------------------------------\n","output_type":"stream"}],"execution_count":119},{"cell_type":"markdown","source":"## With Area class\n","metadata":{}},{"cell_type":"code","source":"# Update target column to 'area_class'\ntarget_column = 'area_class'\n\n# Preprocess and train\n(train_X, test_X, train_y, test_y), label_encoder = preprocess_classification_data(\n    df, target_column, categorical_features, numerical_features\n)\ncategorical_nb(train_X, test_X, train_y, test_y)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T00:09:39.622088Z","iopub.execute_input":"2024-11-21T00:09:39.622778Z","iopub.status.idle":"2024-11-21T00:09:39.643814Z","shell.execute_reply.started":"2024-11-21T00:09:39.622738Z","shell.execute_reply":"2024-11-21T00:09:39.642604Z"}},"outputs":[{"name":"stdout","text":"Categorical Naive Bayes Performance:\nAccuracy: 0.4936\nPrecision: 0.2452\nRecall: 0.4936\nConfusion Matrix:\n[[77  0  0  0]\n [34  0  0  0]\n [27  0  0  0]\n [17  1  0  0]]\n--------------------------------------------------\n","output_type":"stream"}],"execution_count":120},{"cell_type":"markdown","source":"# With area class wihtout class 0","metadata":{}},{"cell_type":"code","source":"# Remove rows where area_class == 0\ndf_filtered = df[df['area_class'] != 0]\n\n# Update target column to 'area_class'\ntarget_column = 'area_class'\nnumerical_features = ['temp', 'RH', 'wind', 'rain']\n\n# Preprocess data for CategoricalNB\n(train_X, test_X, train_y, test_y), label_encoder = preprocess_for_categorical_nb(\n    df_filtered, target_column, numerical_features, n_bins=5\n)\n# Train and evaluate CategoricalNB\ncategorical_nb(train_X, test_X, train_y, test_y)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T00:09:40.735982Z","iopub.execute_input":"2024-11-21T00:09:40.736440Z","iopub.status.idle":"2024-11-21T00:09:40.758079Z","shell.execute_reply.started":"2024-11-21T00:09:40.736402Z","shell.execute_reply":"2024-11-21T00:09:40.756915Z"}},"outputs":[{"name":"stdout","text":"Categorical Naive Bayes Performance:\nAccuracy: 0.4198\nPrecision: 0.4039\nRecall: 0.4198\nConfusion Matrix:\n[[23 16  3]\n [14 10  0]\n [ 8  6  1]]\n--------------------------------------------------\n","output_type":"stream"}],"execution_count":121},{"cell_type":"markdown","source":"## Bernoulli Bayes","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import Binarizer\n\ndef preprocess_for_bernoulli_nb(df, target, numerical_features, threshold=None):\n    \"\"\"\n    Preprocess data for BernoulliNB by binarizing numerical features.\n    \"\"\"\n    # Encode the target as integers\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(df[target])\n    \n    # Binarize numerical features\n    binarizer = Binarizer(threshold=threshold) if threshold else Binarizer()\n    X_binarized = binarizer.fit_transform(df[numerical_features])\n\n    # Return transformed features, target, and binarizer\n    return train_test_split(X_binarized, y, test_size=0.3, random_state=42), label_encoder\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T00:09:41.833379Z","iopub.execute_input":"2024-11-21T00:09:41.833764Z","iopub.status.idle":"2024-11-21T00:09:41.840398Z","shell.execute_reply.started":"2024-11-21T00:09:41.833723Z","shell.execute_reply":"2024-11-21T00:09:41.839189Z"}},"outputs":[],"execution_count":122},{"cell_type":"code","source":"from sklearn.naive_bayes import BernoulliNB\n\ndef cross_validate_bernoulli_nb(X, y):\n    model = BernoulliNB()\n    scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n    \n    print(\"Cross-Validation Results for Bernoulli Naive Bayes:\")\n    print(f\"Accuracy Scores: {scores}\")\n    print(f\"Mean Accuracy: {scores.mean():.4f}\")\n    print(f\"Standard Deviation: {scores.std():.4f}\")\n    print(\"-\" * 50)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T00:09:42.850938Z","iopub.execute_input":"2024-11-21T00:09:42.851360Z","iopub.status.idle":"2024-11-21T00:09:42.857613Z","shell.execute_reply.started":"2024-11-21T00:09:42.851322Z","shell.execute_reply":"2024-11-21T00:09:42.856345Z"}},"outputs":[],"execution_count":123},{"cell_type":"code","source":"def grid_search_bernoulli_nb(X_train, y_train):\n    param_grid = {\n        'alpha': [0.1, 0.5, 1.0, 2.0],  # Smoothing parameter\n        'binarize': [0.0, 0.5, 1.0]  # Threshold for binarization\n    }\n    model = BernoulliNB()\n    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n    grid_search.fit(X_train, y_train)\n    \n    print(\"Grid Search Results for Bernoulli Naive Bayes:\")\n    print(f\"Best Parameters: {grid_search.best_params_}\")\n    print(f\"Best Cross-Validation Accuracy: {grid_search.best_score_:.4f}\")\n    print(\"-\" * 50)\n    return grid_search.best_estimator_\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T00:09:58.743725Z","iopub.execute_input":"2024-11-21T00:09:58.744100Z","iopub.status.idle":"2024-11-21T00:09:58.750754Z","shell.execute_reply.started":"2024-11-21T00:09:58.744068Z","shell.execute_reply":"2024-11-21T00:09:58.749491Z"}},"outputs":[],"execution_count":124},{"cell_type":"code","source":"def bernoulli_nb(X_train, X_test, y_train, y_test):\n    # Cross-validation\n    cross_validate_bernoulli_nb(X_train, y_train)\n\n    # Grid search\n    best_model = grid_search_bernoulli_nb(X_train, y_train)\n\n    # Train the best model on the training set\n    best_model.fit(X_train, y_train)\n    \n    # Make predictions\n    y_pred = best_model.predict(X_test)\n\n    # Evaluate performance\n    accuracy = accuracy_score(y_test, y_pred)\n    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n    recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n    cm = confusion_matrix(y_test, y_pred)\n\n    # Print Metrics\n    print(\"Final Evaluation with Tuned Bernoulli Naive Bayes:\")\n    print(f\"Accuracy: {accuracy:.4f}\")\n    print(f\"Precision: {precision:.4f}\")\n    print(f\"Recall: {recall:.4f}\")\n    print(\"Confusion Matrix:\")\n    print(cm)\n    print(\"-\" * 50)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T00:10:14.561802Z","iopub.execute_input":"2024-11-21T00:10:14.562169Z","iopub.status.idle":"2024-11-21T00:10:14.569918Z","shell.execute_reply.started":"2024-11-21T00:10:14.562137Z","shell.execute_reply":"2024-11-21T00:10:14.568541Z"}},"outputs":[],"execution_count":125},{"cell_type":"markdown","source":"# With area","metadata":{}},{"cell_type":"code","source":"# Define target and features\ntarget_column = 'area'  # Use 'area_class' or other target column\nnumerical_features = ['temp', 'RH', 'wind', 'rain']\n\n# Preprocess data for BernoulliNB\n(train_X, test_X, train_y, test_y), label_encoder = preprocess_for_bernoulli_nb(\n    df, target_column, numerical_features, threshold=0.5  # Example threshold\n)\n\n# Train and evaluate BernoulliNB\nbernoulli_nb(train_X, test_X, train_y, test_y)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T00:16:58.857921Z","iopub.execute_input":"2024-11-21T00:16:58.858367Z","iopub.status.idle":"2024-11-21T00:16:59.006948Z","shell.execute_reply.started":"2024-11-21T00:16:58.858329Z","shell.execute_reply":"2024-11-21T00:16:59.005728Z"}},"outputs":[{"name":"stdout","text":"Cross-Validation Results for Bernoulli Naive Bayes:\nAccuracy Scores: [0.46575342 0.47222222 0.47222222 0.47222222 0.47222222]\nMean Accuracy: 0.4709\nStandard Deviation: 0.0026\n--------------------------------------------------\nGrid Search Results for Bernoulli Naive Bayes:\nBest Parameters: {'alpha': 0.1, 'binarize': 0.0}\nBest Cross-Validation Accuracy: 0.4709\n--------------------------------------------------\nFinal Evaluation with Tuned Bernoulli Naive Bayes:\nAccuracy: 0.4936\nPrecision: 0.2436\nRecall: 0.4936\nConfusion Matrix:\n[[77  0  0 ...  0  0  0]\n [ 1  0  0 ...  0  0  0]\n [ 1  0  0 ...  0  0  0]\n ...\n [ 1  0  0 ...  0  0  0]\n [ 1  0  0 ...  0  0  0]\n [ 1  0  0 ...  0  0  0]]\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":130},{"cell_type":"markdown","source":"# With area class","metadata":{}},{"cell_type":"code","source":"# Define target and features\ntarget_column = 'area_class'  # Use 'area_class' or other target column\nnumerical_features = ['temp', 'RH', 'wind', 'rain']\n\n# Preprocess data for BernoulliNB\n(train_X, test_X, train_y, test_y), label_encoder = preprocess_for_bernoulli_nb(\n    df, target_column, numerical_features, threshold=0.5  # Example threshold\n)\n\n# Train and evaluate BernoulliNB\nbernoulli_nb(train_X, test_X, train_y, test_y)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T00:16:22.253794Z","iopub.execute_input":"2024-11-21T00:16:22.254205Z","iopub.status.idle":"2024-11-21T00:16:22.364183Z","shell.execute_reply.started":"2024-11-21T00:16:22.254168Z","shell.execute_reply":"2024-11-21T00:16:22.363083Z"}},"outputs":[{"name":"stdout","text":"Cross-Validation Results for Bernoulli Naive Bayes:\nAccuracy Scores: [0.46575342 0.47222222 0.47222222 0.47222222 0.47222222]\nMean Accuracy: 0.4709\nStandard Deviation: 0.0026\n--------------------------------------------------\nGrid Search Results for Bernoulli Naive Bayes:\nBest Parameters: {'alpha': 0.1, 'binarize': 0.0}\nBest Cross-Validation Accuracy: 0.4709\n--------------------------------------------------\nFinal Evaluation with Tuned Bernoulli Naive Bayes:\nAccuracy: 0.5000\nPrecision: 0.4632\nRecall: 0.5000\nConfusion Matrix:\n[[77  0  0  0]\n [33  1  0  0]\n [27  0  0  0]\n [18  0  0  0]]\n--------------------------------------------------\n","output_type":"stream"}],"execution_count":129},{"cell_type":"markdown","source":"# With area class excluding class 0","metadata":{}},{"cell_type":"code","source":"# Remove rows where area_class == 0\ndf_filtered = df[df['area_class'] != 0]\n\n# Update target column to 'area_class'\ntarget_column = 'area_class'\nnumerical_features = ['temp', 'RH', 'wind', 'rain']\n\n# Preprocess data for CategoricalNB\n(train_X, test_X, train_y, test_y), label_encoder = preprocess_for_categorical_nb(\n    df_filtered, target_column, numerical_features, n_bins=5\n)\n# Train and evaluate CategoricalNB\nbernoulli_nb(train_X, test_X, train_y, test_y)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T00:17:40.786015Z","iopub.execute_input":"2024-11-21T00:17:40.786444Z","iopub.status.idle":"2024-11-21T00:17:40.904184Z","shell.execute_reply.started":"2024-11-21T00:17:40.786405Z","shell.execute_reply":"2024-11-21T00:17:40.903069Z"}},"outputs":[{"name":"stdout","text":"Cross-Validation Results for Bernoulli Naive Bayes:\nAccuracy Scores: [0.47368421 0.39473684 0.44736842 0.39473684 0.35135135]\nMean Accuracy: 0.4124\nStandard Deviation: 0.0432\n--------------------------------------------------\nGrid Search Results for Bernoulli Naive Bayes:\nBest Parameters: {'alpha': 0.5, 'binarize': 1.0}\nBest Cross-Validation Accuracy: 0.4502\n--------------------------------------------------\nFinal Evaluation with Tuned Bernoulli Naive Bayes:\nAccuracy: 0.5185\nPrecision: 0.3983\nRecall: 0.5185\nConfusion Matrix:\n[[36  6  0]\n [18  6  0]\n [11  4  0]]\n--------------------------------------------------\n","output_type":"stream"}],"execution_count":131},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}