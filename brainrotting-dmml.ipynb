{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-20T22:08:11.170565Z",
     "iopub.status.busy": "2024-11-20T22:08:11.169499Z",
     "iopub.status.idle": "2024-11-20T22:08:11.178786Z",
     "shell.execute_reply": "2024-11-20T22:08:11.177518Z",
     "shell.execute_reply.started": "2024-11-20T22:08:11.170523Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/forest-fires-regression/forestfires.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T22:25:57.351954Z",
     "iopub.status.busy": "2024-11-20T22:25:57.349772Z",
     "iopub.status.idle": "2024-11-20T22:25:57.362297Z",
     "shell.execute_reply": "2024-11-20T22:25:57.360923Z",
     "shell.execute_reply.started": "2024-11-20T22:25:57.351902Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, OneHotEncoder, LabelEncoder, KBinsDiscretizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, make_scorer, classification_report, confusion_matrix, roc_auc_score, make_scorer\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forest Fire data representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T22:08:13.257008Z",
     "iopub.status.busy": "2024-11-20T22:08:13.256585Z",
     "iopub.status.idle": "2024-11-20T22:08:13.302291Z",
     "shell.execute_reply": "2024-11-20T22:08:13.301241Z",
     "shell.execute_reply.started": "2024-11-20T22:08:13.256974Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.669246</td>\n",
       "      <td>4.299807</td>\n",
       "      <td>90.644681</td>\n",
       "      <td>110.872340</td>\n",
       "      <td>547.940039</td>\n",
       "      <td>9.021663</td>\n",
       "      <td>18.889168</td>\n",
       "      <td>44.288201</td>\n",
       "      <td>4.017602</td>\n",
       "      <td>0.021663</td>\n",
       "      <td>12.847292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.313778</td>\n",
       "      <td>1.229900</td>\n",
       "      <td>5.520111</td>\n",
       "      <td>64.046482</td>\n",
       "      <td>248.066192</td>\n",
       "      <td>4.559477</td>\n",
       "      <td>5.806625</td>\n",
       "      <td>16.317469</td>\n",
       "      <td>1.791653</td>\n",
       "      <td>0.295959</td>\n",
       "      <td>63.655818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>18.700000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>90.200000</td>\n",
       "      <td>68.600000</td>\n",
       "      <td>437.700000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>91.600000</td>\n",
       "      <td>108.300000</td>\n",
       "      <td>664.200000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>19.300000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>92.900000</td>\n",
       "      <td>142.400000</td>\n",
       "      <td>713.900000</td>\n",
       "      <td>10.800000</td>\n",
       "      <td>22.800000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.570000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>96.200000</td>\n",
       "      <td>291.300000</td>\n",
       "      <td>860.600000</td>\n",
       "      <td>56.100000</td>\n",
       "      <td>33.300000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>1090.840000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                X           Y        FFMC         DMC          DC         ISI  \\\n",
       "count  517.000000  517.000000  517.000000  517.000000  517.000000  517.000000   \n",
       "mean     4.669246    4.299807   90.644681  110.872340  547.940039    9.021663   \n",
       "std      2.313778    1.229900    5.520111   64.046482  248.066192    4.559477   \n",
       "min      1.000000    2.000000   18.700000    1.100000    7.900000    0.000000   \n",
       "25%      3.000000    4.000000   90.200000   68.600000  437.700000    6.500000   \n",
       "50%      4.000000    4.000000   91.600000  108.300000  664.200000    8.400000   \n",
       "75%      7.000000    5.000000   92.900000  142.400000  713.900000   10.800000   \n",
       "max      9.000000    9.000000   96.200000  291.300000  860.600000   56.100000   \n",
       "\n",
       "             temp          RH        wind        rain         area  \n",
       "count  517.000000  517.000000  517.000000  517.000000   517.000000  \n",
       "mean    18.889168   44.288201    4.017602    0.021663    12.847292  \n",
       "std      5.806625   16.317469    1.791653    0.295959    63.655818  \n",
       "min      2.200000   15.000000    0.400000    0.000000     0.000000  \n",
       "25%     15.500000   33.000000    2.700000    0.000000     0.000000  \n",
       "50%     19.300000   42.000000    4.000000    0.000000     0.520000  \n",
       "75%     22.800000   53.000000    4.900000    0.000000     6.570000  \n",
       "max     33.300000  100.000000    9.400000    6.400000  1090.840000  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/forest-fires-regression/forestfires.csv\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing diff models and algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions & Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T22:08:15.288511Z",
     "iopub.status.busy": "2024-11-20T22:08:15.287654Z",
     "iopub.status.idle": "2024-11-20T22:08:15.294121Z",
     "shell.execute_reply": "2024-11-20T22:08:15.293020Z",
     "shell.execute_reply.started": "2024-11-20T22:08:15.288464Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model_name, y_test, y_pred):\n",
    "    mad = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    print(f\"{model_name} Performance:\")\n",
    "    print(f\"Mean Absolute Deviation (MAD): {mad}\")\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T22:08:15.942417Z",
     "iopub.status.busy": "2024-11-20T22:08:15.942047Z",
     "iopub.status.idle": "2024-11-20T22:08:15.950184Z",
     "shell.execute_reply": "2024-11-20T22:08:15.948765Z",
     "shell.execute_reply.started": "2024-11-20T22:08:15.942384Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "numerical_features = ['temp', 'RH', 'wind', 'rain']  \n",
    "categorical_features = []  \n",
    "# Preprocess the data\n",
    "def preprocess_data(df, target, categorical_features, numerical_features):\n",
    "    # Log-transform the target variable\n",
    "    y = np.log1p(df[target])  \n",
    "    \n",
    "    # Remove the target column from the features\n",
    "    X = df.drop(columns=[target])\n",
    "    \n",
    "    # Define transformers\n",
    "    preprocess = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numerical_features),\n",
    "            ('cat', OneHotEncoder(), categorical_features)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Apply transformations\n",
    "    X_transformed = preprocess.fit_transform(X)\n",
    "    \n",
    "    # Split the dataset into train and test sets\n",
    "    return train_test_split(X_transformed, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T22:08:16.601922Z",
     "iopub.status.busy": "2024-11-20T22:08:16.601548Z",
     "iopub.status.idle": "2024-11-20T22:08:16.607701Z",
     "shell.execute_reply": "2024-11-20T22:08:16.606505Z",
     "shell.execute_reply.started": "2024-11-20T22:08:16.601890Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def neural_network(X_train, X_test, y_train, y_test):\n",
    "    model = MLPRegressor(hidden_layer_sizes=(10,), max_iter=1000, solver='adam',learning_rate_init=0.001,early_stopping=True, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    evaluate_model(\"Neural Network\", y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimimzing MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T22:08:17.341593Z",
     "iopub.status.busy": "2024-11-20T22:08:17.341169Z",
     "iopub.status.idle": "2024-11-20T22:08:17.350484Z",
     "shell.execute_reply": "2024-11-20T22:08:17.349317Z",
     "shell.execute_reply.started": "2024-11-20T22:08:17.341555Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Cross-Validation for MLP\n",
    "def cross_validate_mlp(X, y):\n",
    "    model = MLPRegressor(hidden_layer_sizes=(10,), max_iter=500, solver='adam', learning_rate_init=0.001, random_state=42)\n",
    "    scorer = make_scorer(mean_squared_error, squared=False)\n",
    "    scores = cross_val_score(model, X, y, cv=5, scoring=scorer)\n",
    "    print(\"Cross-validated RMSE scores:\", scores)\n",
    "    print(\"Mean RMSE:\", scores.mean())\n",
    "\n",
    "# Hyperparameter Tuning for MLP\n",
    "def tune_mlp(X_train, y_train):\n",
    "    param_grid = {\n",
    "        'hidden_layer_sizes': [(10,), (50,), (100,)],\n",
    "        'learning_rate_init': [0.001, 0.01, 0.1],\n",
    "        'solver': ['adam', 'sgd'],\n",
    "        'max_iter': [500, 1000]\n",
    "    }\n",
    "    \n",
    "    model = MLPRegressor(random_state=42, early_stopping=True)\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_model = grid_search.best_estimator_\n",
    "    print(\"Best Parameters:\", grid_search.best_params_)\n",
    "    print(\"Best RMSE:\", np.sqrt(-grid_search.best_score_))\n",
    "    return best_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T22:08:18.071971Z",
     "iopub.status.busy": "2024-11-20T22:08:18.071522Z",
     "iopub.status.idle": "2024-11-20T22:08:25.279628Z",
     "shell.execute_reply": "2024-11-20T22:08:25.278404Z",
     "shell.execute_reply.started": "2024-11-20T22:08:18.071937Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Results for MLP:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated RMSE scores: [1.41556921 1.26431999 1.70147067 1.54545318 1.26838491]\n",
      "Mean RMSE: 1.4390395931493056\n",
      "\n",
      "Hyperparameter Tuning for MLP:\n",
      "Best Parameters: {'hidden_layer_sizes': (50,), 'learning_rate_init': 0.001, 'max_iter': 500, 'solver': 'sgd'}\n",
      "Best RMSE: 1.3859581187939796\n",
      "Tuned MLP Regressor Performance:\n",
      "Mean Absolute Deviation (MAD): 1.1573045980401029\n",
      "Root Mean Squared Error (RMSE): 1.453821275015725\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define target and features\n",
    "target_column = 'area'\n",
    "numerical_features = ['temp', 'RH', 'wind', 'rain']\n",
    "categorical_features = []  # Add categorical features if needed\n",
    "\n",
    "# Preprocess data\n",
    "X_train, X_test, y_train, y_test = preprocess_data(df, target_column, categorical_features, numerical_features)\n",
    "\n",
    "# Cross-validate MLP\n",
    "print(\"Cross-Validation Results for MLP:\")\n",
    "cross_validate_mlp(X_train, y_train)\n",
    "\n",
    "# Hyperparameter tuning for MLP\n",
    "print(\"\\nHyperparameter Tuning for MLP:\")\n",
    "best_mlp = tune_mlp(X_train, y_train)\n",
    "\n",
    "# Evaluate best MLP on the test set\n",
    "y_pred = best_mlp.predict(X_test)\n",
    "evaluate_model(\"Tuned MLP Regressor\", y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T22:08:25.282013Z",
     "iopub.status.busy": "2024-11-20T22:08:25.281533Z",
     "iopub.status.idle": "2024-11-20T22:08:25.290561Z",
     "shell.execute_reply": "2024-11-20T22:08:25.288707Z",
     "shell.execute_reply.started": "2024-11-20T22:08:25.281962Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def support_vector_machine(X_train, X_test, y_train, y_test):\n",
    "    model = SVR(kernel='rbf', C=3, epsilon=0.1, gamma='scale')\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    evaluate_model(\"Support Vector Machine\", y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T22:08:25.295298Z",
     "iopub.status.busy": "2024-11-20T22:08:25.293208Z",
     "iopub.status.idle": "2024-11-20T22:08:25.315988Z",
     "shell.execute_reply": "2024-11-20T22:08:25.314627Z",
     "shell.execute_reply.started": "2024-11-20T22:08:25.295229Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Cross-validate SVM\n",
    "def cross_validate_svm(X, y):\n",
    "    model = SVR(kernel='rbf', C=3, epsilon=0.1, gamma='scale')\n",
    "    scorer = make_scorer(mean_squared_error, squared=False)  # Use RMSE\n",
    "    scores = cross_val_score(model, X, y, cv=5, scoring=scorer)\n",
    "    \n",
    "    # Print cross-validation scores\n",
    "    print(\"Cross-Validation Results for SVM:\")\n",
    "    for i, score in enumerate(scores, 1):\n",
    "        print(f\"Fold {i}: RMSE = {score:.4f}\")\n",
    "    print(f\"Mean RMSE: {np.mean(scores):.4f}\")\n",
    "    print(f\"Standard Deviation of RMSE: {np.std(scores):.4f}\\n\")\n",
    "\n",
    "# Hyperparameter tuning for SVM\n",
    "def tune_svm(X_train, y_train):\n",
    "    param_grid = {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'epsilon': [0.01, 0.1, 0.5, 1],\n",
    "        'gamma': ['scale', 'auto', 0.01, 0.1]\n",
    "    }\n",
    "    model = SVR(kernel='rbf')\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Extract best parameters and results\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = np.sqrt(-grid_search.best_score_)  # Convert negative MSE to RMSE\n",
    "    \n",
    "    print(\"Hyperparameter Tuning Results for SVM:\")\n",
    "    print(f\"Best Parameters: {best_params}\")\n",
    "    print(f\"Best RMSE: {best_score:.4f}\\n\")\n",
    "    \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T22:08:25.319154Z",
     "iopub.status.busy": "2024-11-20T22:08:25.318196Z",
     "iopub.status.idle": "2024-11-20T22:08:27.511759Z",
     "shell.execute_reply": "2024-11-20T22:08:27.510544Z",
     "shell.execute_reply.started": "2024-11-20T22:08:25.319098Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Results for SVM:\n",
      "Cross-Validation Results for SVM:\n",
      "Fold 1: RMSE = 1.4865\n",
      "Fold 2: RMSE = 1.4091\n",
      "Fold 3: RMSE = 1.6665\n",
      "Fold 4: RMSE = 1.6731\n",
      "Fold 5: RMSE = 1.2988\n",
      "Mean RMSE: 1.5068\n",
      "Standard Deviation of RMSE: 0.1458\n",
      "\n",
      "\n",
      "Hyperparameter Tuning for SVM:\n",
      "Hyperparameter Tuning Results for SVM:\n",
      "Best Parameters: {'C': 100, 'epsilon': 1, 'gamma': 0.01}\n",
      "Best RMSE: 1.3699\n",
      "\n",
      "Tuned Support Vector Machine Performance:\n",
      "Mean Absolute Deviation (MAD): 1.1675611358607194\n",
      "Root Mean Squared Error (RMSE): 1.4712687197338465\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate SVM\n",
    "print(\"Cross-Validation Results for SVM:\")\n",
    "cross_validate_svm(X_train, y_train)\n",
    "\n",
    "print(\"\\nHyperparameter Tuning for SVM:\")\n",
    "best_svm = tune_svm(X_train, y_train)\n",
    "\n",
    "# Evaluate best SVM on the test set\n",
    "y_pred = best_svm.predict(X_test)\n",
    "evaluate_model(\"Tuned Support Vector Machine\", y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Algorithms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T23:04:26.214594Z",
     "iopub.status.busy": "2024-11-20T23:04:26.214153Z",
     "iopub.status.idle": "2024-11-20T23:04:26.226659Z",
     "shell.execute_reply": "2024-11-20T23:04:26.225473Z",
     "shell.execute_reply.started": "2024-11-20T23:04:26.214557Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution for 'area_class':\n",
      "area_class\n",
      "0    247\n",
      "1    119\n",
      "2     92\n",
      "3     59\n",
      "Name: count, dtype: int64\n",
      "Class distribution for 'area_class':\n",
      "area_class\n",
      "0    247\n",
      "1    119\n",
      "2     92\n",
      "3     59\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define the classification function\n",
    "def classify_area(area):\n",
    "    if area == 0:\n",
    "        return 0  # No fire\n",
    "    elif area <= 5:\n",
    "        return 1  # Small fire\n",
    "    elif area <= 20:\n",
    "        return 2  # Medium fire\n",
    "    else:\n",
    "        return 3  # Large fire\n",
    "\n",
    "# Apply the function to create a new column\n",
    "df['area_class'] = df['area'].apply(classify_area)\n",
    "\n",
    "# Check the class distribution\n",
    "print(\"Class distribution for 'area_class':\")\n",
    "print(df['area_class'].value_counts())# Define the classification function\n",
    "def classify_area(area):\n",
    "    if area == 0:\n",
    "        return 0  # No fire\n",
    "    elif area <= 5:\n",
    "        return 1  # Small fire\n",
    "    elif area <= 20:\n",
    "        return 2  # Medium fire\n",
    "    else:\n",
    "        return 3  # Large fire\n",
    "\n",
    "# Apply the function to create a new column\n",
    "df['area_class'] = df['area'].apply(classify_area)\n",
    "\n",
    "# Check the class distribution\n",
    "print(\"Class distribution for 'area_class':\")\n",
    "print(df['area_class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T23:04:29.290930Z",
     "iopub.status.busy": "2024-11-20T23:04:29.290461Z",
     "iopub.status.idle": "2024-11-20T23:04:29.297687Z",
     "shell.execute_reply": "2024-11-20T23:04:29.296382Z",
     "shell.execute_reply.started": "2024-11-20T23:04:29.290887Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def preprocess_classification_data(df, target, categorical_features, numerical_features):\n",
    "    # Encode target labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    y = label_encoder.fit_transform(df[target])  # Converts target labels to integers\n",
    "\n",
    "    # Define preprocessing for features\n",
    "    preprocess = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"cat\", OneHotEncoder(), categorical_features),  # One-hot encode categorical features\n",
    "            (\"num\", MinMaxScaler(), numerical_features),  # Min-max scale numerical features\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Apply transformations to input features\n",
    "    X = preprocess.fit_transform(df.drop(columns=[target]))\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    return train_test_split(X, y, test_size=0.3, random_state=42), label_encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Bayes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def calculate_specificity(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn = cm[0, 0]  # True Negatives\n",
    "    fp = cm[0, 1]  # False Positives\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    return specificity\n",
    "def multinomial_nb(X_train, X_test, y_train, y_test):\n",
    "    # Initialize the model\n",
    "    model = MultinomialNB()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1] if len(model.classes_) == 2 else None\n",
    "\n",
    "    # Metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    specificity = calculate_specificity(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_proba) if y_proba is not None else \"Not applicable for multiclass\"\n",
    "\n",
    "    # Print Metrics\n",
    "    print(\"Multinomial Naive Bayes Performance:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall (Sensitivity): {recall:.4f}\")\n",
    "    print(f\"Specificity: {specificity:.4f}\")\n",
    "    if y_proba is not None:\n",
    "        print(f\"AUC: {auc:.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T23:05:49.736108Z",
     "iopub.status.busy": "2024-11-20T23:05:49.735620Z",
     "iopub.status.idle": "2024-11-20T23:05:49.760392Z",
     "shell.execute_reply": "2024-11-20T23:05:49.759216Z",
     "shell.execute_reply.started": "2024-11-20T23:05:49.736070Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes Performance:\n",
      "Accuracy: 0.4936\n",
      "Precision: 0.2436\n",
      "Recall (Sensitivity): 0.4936\n",
      "Specificity: 1.0000\n",
      "Confusion Matrix:\n",
      "[[77  0  0 ...  0  0  0]\n",
      " [ 1  0  0 ...  0  0  0]\n",
      " [ 1  0  0 ...  0  0  0]\n",
      " ...\n",
      " [ 1  0  0 ...  0  0  0]\n",
      " [ 1  0  0 ...  0  0  0]\n",
      " [ 1  0  0 ...  0  0  0]]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Define target and features\n",
    "target_column = 'area'  # Burned area column\n",
    "categorical_features = []  # Replace with categorical feature names if available\n",
    "numerical_features = ['temp', 'RH', 'wind', 'rain']  # Numerical feature names from dataset\n",
    "\n",
    "# Preprocess the dataset\n",
    "(train_X, test_X, train_y, test_y), label_encoder = preprocess_classification_data(\n",
    "    df, target_column, categorical_features, numerical_features\n",
    ")\n",
    "\n",
    "# Train and evaluate Multinomial Naive Bayes\n",
    "multinomial_nb(train_X, test_X, train_y, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With class 0 evaluating with area class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T23:06:18.048717Z",
     "iopub.status.busy": "2024-11-20T23:06:18.048278Z",
     "iopub.status.idle": "2024-11-20T23:06:18.072306Z",
     "shell.execute_reply": "2024-11-20T23:06:18.071068Z",
     "shell.execute_reply.started": "2024-11-20T23:06:18.048676Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes Performance:\n",
      "Accuracy: 0.4936\n",
      "Precision: 0.2436\n",
      "Recall (Sensitivity): 0.4936\n",
      "Specificity: 1.0000\n",
      "Confusion Matrix:\n",
      "[[77  0  0  0]\n",
      " [34  0  0  0]\n",
      " [27  0  0  0]\n",
      " [18  0  0  0]]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Define target and features\n",
    "target_column = 'area_class'  # New target column\n",
    "categorical_features = []  # Replace with categorical feature names\n",
    "numerical_features = ['temp', 'RH', 'wind', 'rain']  # Numerical feature names\n",
    "\n",
    "\n",
    "# Preprocess the dataset\n",
    "(train_X, test_X, train_y, test_y), label_encoder = preprocess_classification_data(\n",
    "    df, target_column, categorical_features, numerical_features\n",
    ")\n",
    "\n",
    "# Train and evaluate Multinomial Naive Bayes\n",
    "multinomial_nb(train_X, test_X, train_y, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without class 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T23:06:50.652571Z",
     "iopub.status.busy": "2024-11-20T23:06:50.651585Z",
     "iopub.status.idle": "2024-11-20T23:06:50.667577Z",
     "shell.execute_reply": "2024-11-20T23:06:50.666320Z",
     "shell.execute_reply.started": "2024-11-20T23:06:50.652526Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Remove rows where area_class == 0\n",
    "df_filtered = df[df['area_class'] != 0]\n",
    "\n",
    "# Update target and features\n",
    "target_column = 'area_class'\n",
    "categorical_features = []  # Replace with categorical features if available\n",
    "numerical_features = ['temp', 'RH', 'wind', 'rain']\n",
    "\n",
    "# Preprocess the filtered dataset\n",
    "(train_X, test_X, train_y, test_y), label_encoder = preprocess_classification_data(\n",
    "    df_filtered, target_column, categorical_features, numerical_features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5946338,
     "sourceId": 9719332,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
