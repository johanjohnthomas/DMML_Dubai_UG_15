{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n@inproceedings{taniguchi2024adopt,\\n author={Taniguchi, Shohei and Harada, Keno and Minegishi, Gouki and Oshima, Yuta and Jeong, Seong Cheol and Nagahara, Go and Iiyama, Tomoshi and Suzuki, Masahiro and Iwasawa, Yusuke and Matsuo, Yutaka},\\n booktitle = {Advances in Neural Information Processing Systems},\\n title = {ADOPT: Modified Adam Can Converge with Any β2 with the Optimal Rate},\\n year = {2024}\\n}\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from glob import glob\n",
    "from PIL import Image, ImageFile\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, precision_recall_fscore_support\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "from torch.optim import Adam\n",
    "from torchvision import datasets\n",
    "from adopt import ADOPT\n",
    "from torch.optim import Adam\n",
    "\"\"\"\n",
    "@inproceedings{taniguchi2024adopt,\n",
    " author={Taniguchi, Shohei and Harada, Keno and Minegishi, Gouki and Oshima, Yuta and Jeong, Seong Cheol and Nagahara, Go and Iiyama, Tomoshi and Suzuki, Masahiro and Iwasawa, Yusuke and Matsuo, Yutaka},\n",
    " booktitle = {Advances in Neural Information Processing Systems},\n",
    " title = {ADOPT: Modified Adam Can Converge with Any β2 with the Optimal Rate},\n",
    " year = {2024}\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "ROOT_DIR = \"Datasets/corrected_wildfires_dataset\"\n",
    "IMAGE_SIZE = (224, 224)\n",
    "MEAN = [0.485, 0.456, 0.406]  # Normalization mean\n",
    "STD = [0.229, 0.224, 0.225]   # Normalization std\n",
    "NUM_FOLDS = 10\n",
    "NUM_EPOCHS = 10\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "# Hyperparameter ranges for tuning\n",
    "learning_rates = [0.01, 0.001, 0.0001]\n",
    "dropout_rates = [0.3, 0.5]\n",
    "batch_sizes = [16, 32]\n",
    "num_conv_layers_list = [2, 3]\n",
    "num_filters_list = [[32, 64], [64, 128]]\n",
    "fc_units_list = [128, 256]\n",
    "\n",
    "# Suppress PIL DecompressionBombWarning and handle large images\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True  # Handle truncated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation and normalization\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((256, 256)),  # Resize images to a reasonable size\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),  # Small rotation\n",
    "        transforms.RandomResizedCrop(IMAGE_SIZE[0], scale=(0.9, 1.0)),  # Small random zoom in\n",
    "        transforms.ColorJitter(contrast=0.1),  # Small random contrast\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(MEAN, STD)\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((256, 256)),  # Resize images to a reasonable size\n",
    "        transforms.CenterCrop(IMAGE_SIZE),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(MEAN, STD)\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Custom Dataset class for loading images and labels.\n",
    "    \"\"\"\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"Return the total number of samples.\"\"\"\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Generate one sample of data.\"\"\"\n",
    "        image_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        try:\n",
    "            image = Image.open(image_path).convert(\"RGB\")\n",
    "        except Exception as e:\n",
    "            # If image is corrupted, replace it with a black image\n",
    "            print(f\"Warning: Unable to open image {image_path}. Error: {e}\")\n",
    "            image = Image.new('RGB', IMAGE_SIZE)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before balancing: {0: 469, 1: 990}\n"
     ]
    }
   ],
   "source": [
    "# Prepare dataset and labels\n",
    "image_paths = glob(f\"{ROOT_DIR}/*/*.jpg\")\n",
    "class_labels = {\"fire\": 0, \"nofire\": 1}\n",
    "\n",
    "# Filter image paths and extract labels\n",
    "filtered_image_paths = []\n",
    "labels = []\n",
    "for p in image_paths:\n",
    "    label_name = os.path.basename(os.path.dirname(p))\n",
    "    if label_name in class_labels:\n",
    "        filtered_image_paths.append(p)\n",
    "        labels.append(class_labels[label_name])\n",
    "\n",
    "# Convert to numpy arrays\n",
    "image_paths = np.array(filtered_image_paths)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Check class distribution before balancing\n",
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "class_counts = dict(zip(unique, counts))\n",
    "print(\"Class distribution before balancing:\", class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution after balancing: {0: 469, 1: 469}\n"
     ]
    }
   ],
   "source": [
    "# Balance the classes by undersampling the majority class\n",
    "min_count = min(class_counts.values())\n",
    "\n",
    "balanced_image_paths = []\n",
    "balanced_labels = []\n",
    "\n",
    "for class_label in np.unique(labels):\n",
    "    class_indices = np.where(labels == class_label)[0]\n",
    "    sampled_indices = np.random.choice(class_indices, min_count, replace=False)\n",
    "    balanced_image_paths.extend(image_paths[sampled_indices])\n",
    "    balanced_labels.extend([class_label] * min_count)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "balanced_image_paths = np.array(balanced_image_paths)\n",
    "balanced_labels = np.array(balanced_labels)\n",
    "\n",
    "# Shuffle the balanced dataset\n",
    "indices = np.arange(len(balanced_image_paths))\n",
    "np.random.shuffle(indices)\n",
    "balanced_image_paths = balanced_image_paths[indices]\n",
    "balanced_labels = balanced_labels[indices]\n",
    "\n",
    "# Update image_paths and labels to the balanced dataset\n",
    "image_paths = balanced_image_paths\n",
    "labels = balanced_labels\n",
    "\n",
    "# Check class distribution after balancing\n",
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "class_counts = dict(zip(unique, counts))\n",
    "print(\"Class distribution after balancing:\", class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and validation sets\n",
    "train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "    image_paths, labels, test_size=0.2, stratify=labels, random_state=42\n",
    ")\n",
    "\n",
    "# Create a list of hyperparameter combinations\n",
    "hyperparameter_list = []\n",
    "\n",
    "for lr, dr, bs, ncl, nf, fc in product(learning_rates, dropout_rates, batch_sizes, num_conv_layers_list, num_filters_list, fc_units_list):\n",
    "    if len(nf) >= ncl:\n",
    "        architecture = {\n",
    "            'name': f\"Model_lr{lr}_dr{dr}_bs{bs}_ncl{ncl}_nf{'_'.join(map(str, nf[:ncl]))}_fc{fc}\",\n",
    "            'num_conv_layers': ncl,\n",
    "            'num_filters': nf[:ncl],\n",
    "            'kernel_sizes': [3]*ncl,\n",
    "            'fc_units': fc,\n",
    "            'dropout_rate': dr,\n",
    "            'learning_rate': lr,\n",
    "            'batch_size': bs,\n",
    "            'optimizer': 'adam'\n",
    "        }\n",
    "        hyperparameter_list.append(architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Convolutional Neural Network Model.\n",
    "    \"\"\"\n",
    "    def __init__(self, architecture):\n",
    "        super(CNNModel, self).__init__()\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        # Build convolutional layers\n",
    "        for i in range(architecture['num_conv_layers']):\n",
    "            out_channels = architecture['num_filters'][i]\n",
    "            layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=architecture['kernel_sizes'][i], padding=1))\n",
    "            layers.append(nn.BatchNorm2d(out_channels))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "            layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "            in_channels = out_channels\n",
    "        self.features = nn.Sequential(*layers)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        # Fully connected layers\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_channels, architecture['fc_units']),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(architecture['dropout_rate']),\n",
    "            nn.Linear(architecture['fc_units'], NUM_CLASSES)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Model:\n",
      "Model Name: Model_lr0.01_dr0.3_bs16_ncl2_nf32_64_fc128\n",
      "Learning Rate: 0.01\n",
      "Dropout Rate: 0.3\n",
      "Batch Size: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 Training:   0%|          | 0/47 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 Training: 100%|██████████| 47/47 [02:10<00:00,  2.78s/it]\n",
      "Epoch 1/10 Validation: 100%|██████████| 12/12 [00:34<00:00,  2.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Acc: 0.6760, Val Acc: 0.7234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 Training: 100%|██████████| 47/47 [02:13<00:00,  2.84s/it]\n",
      "Epoch 2/10 Validation: 100%|██████████| 12/12 [00:34<00:00,  2.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Acc: 0.6893, Val Acc: 0.7766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 Training: 100%|██████████| 47/47 [02:14<00:00,  2.87s/it]\n",
      "Epoch 3/10 Validation: 100%|██████████| 12/12 [00:35<00:00,  2.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Acc: 0.7200, Val Acc: 0.7819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 Training: 100%|██████████| 47/47 [02:11<00:00,  2.80s/it]\n",
      "Epoch 4/10 Validation: 100%|██████████| 12/12 [00:35<00:00,  2.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Acc: 0.7147, Val Acc: 0.7606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 Training: 100%|██████████| 47/47 [02:14<00:00,  2.87s/it]\n",
      "Epoch 5/10 Validation: 100%|██████████| 12/12 [00:35<00:00,  2.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Acc: 0.7107, Val Acc: 0.7447\n",
      "Early stopping\n",
      "\n",
      "Evaluating Model:\n",
      "Model Name: Model_lr0.01_dr0.3_bs16_ncl2_nf32_64_fc256\n",
      "Learning Rate: 0.01\n",
      "Dropout Rate: 0.3\n",
      "Batch Size: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 Training: 100%|██████████| 47/47 [02:16<00:00,  2.91s/it]\n",
      "Epoch 1/10 Validation: 100%|██████████| 12/12 [00:35<00:00,  2.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Acc: 0.6520, Val Acc: 0.6596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 Training: 100%|██████████| 47/47 [02:13<00:00,  2.83s/it]\n",
      "Epoch 2/10 Validation: 100%|██████████| 12/12 [00:35<00:00,  2.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Acc: 0.7040, Val Acc: 0.6862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 Training: 100%|██████████| 47/47 [02:14<00:00,  2.86s/it]\n",
      "Epoch 3/10 Validation: 100%|██████████| 12/12 [00:35<00:00,  2.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Acc: 0.7147, Val Acc: 0.7394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 Training: 100%|██████████| 47/47 [02:16<00:00,  2.91s/it]\n",
      "Epoch 4/10 Validation: 100%|██████████| 12/12 [00:35<00:00,  2.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Acc: 0.6867, Val Acc: 0.6968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 Training: 100%|██████████| 47/47 [02:15<00:00,  2.87s/it]\n",
      "Epoch 5/10 Validation: 100%|██████████| 12/12 [00:35<00:00,  2.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Acc: 0.7027, Val Acc: 0.7713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 Training: 100%|██████████| 47/47 [02:15<00:00,  2.88s/it]\n",
      "Epoch 6/10 Validation: 100%|██████████| 12/12 [00:35<00:00,  2.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Acc: 0.7387, Val Acc: 0.7819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 Training: 100%|██████████| 47/47 [02:14<00:00,  2.85s/it]\n",
      "Epoch 7/10 Validation: 100%|██████████| 12/12 [00:35<00:00,  2.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Train Acc: 0.7200, Val Acc: 0.7447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 Training: 100%|██████████| 47/47 [02:14<00:00,  2.86s/it]\n",
      "Epoch 8/10 Validation: 100%|██████████| 12/12 [00:35<00:00,  2.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Train Acc: 0.7280, Val Acc: 0.7872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 Training: 100%|██████████| 47/47 [02:14<00:00,  2.86s/it]\n",
      "Epoch 9/10 Validation: 100%|██████████| 12/12 [00:35<00:00,  2.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Train Acc: 0.7133, Val Acc: 0.7766\n",
      "Early stopping\n",
      "\n",
      "Evaluating Model:\n",
      "Model Name: Model_lr0.01_dr0.3_bs16_ncl2_nf64_128_fc128\n",
      "Learning Rate: 0.01\n",
      "Dropout Rate: 0.3\n",
      "Batch Size: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 Training: 100%|██████████| 47/47 [02:16<00:00,  2.91s/it]\n",
      "Epoch 1/10 Validation: 100%|██████████| 12/12 [00:35<00:00,  2.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Acc: 0.6307, Val Acc: 0.7340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 Training: 100%|██████████| 47/47 [02:14<00:00,  2.87s/it]\n",
      "Epoch 2/10 Validation: 100%|██████████| 12/12 [00:35<00:00,  2.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Acc: 0.6840, Val Acc: 0.7287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 Training: 100%|██████████| 47/47 [02:16<00:00,  2.90s/it]\n",
      "Epoch 3/10 Validation: 100%|██████████| 12/12 [00:35<00:00,  2.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Acc: 0.6907, Val Acc: 0.7500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 Training: 100%|██████████| 47/47 [02:16<00:00,  2.90s/it]\n",
      "Epoch 4/10 Validation: 100%|██████████| 12/12 [00:35<00:00,  2.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Acc: 0.7000, Val Acc: 0.7553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 Training: 100%|██████████| 47/47 [02:14<00:00,  2.87s/it]\n",
      "Epoch 5/10 Validation: 100%|██████████| 12/12 [00:35<00:00,  2.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Acc: 0.7160, Val Acc: 0.7713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 Training: 100%|██████████| 47/47 [02:16<00:00,  2.90s/it]\n",
      "Epoch 6/10 Validation: 100%|██████████| 12/12 [00:35<00:00,  2.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Acc: 0.6987, Val Acc: 0.7394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 Training: 100%|██████████| 47/47 [02:15<00:00,  2.89s/it]\n",
      "Epoch 7/10 Validation: 100%|██████████| 12/12 [00:35<00:00,  2.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Train Acc: 0.7013, Val Acc: 0.7287\n",
      "Early stopping\n",
      "\n",
      "Evaluating Model:\n",
      "Model Name: Model_lr0.01_dr0.3_bs16_ncl2_nf64_128_fc256\n",
      "Learning Rate: 0.01\n",
      "Dropout Rate: 0.3\n",
      "Batch Size: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 Training: 100%|██████████| 47/47 [02:16<00:00,  2.91s/it]\n",
      "Epoch 1/10 Validation: 100%|██████████| 12/12 [00:35<00:00,  2.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Acc: 0.6373, Val Acc: 0.7553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 Training: 100%|██████████| 47/47 [02:14<00:00,  2.87s/it]\n",
      "Epoch 2/10 Validation: 100%|██████████| 12/12 [00:35<00:00,  2.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Acc: 0.7000, Val Acc: 0.7447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 Training: 100%|██████████| 47/47 [02:12<00:00,  2.82s/it]\n",
      "Epoch 3/10 Validation: 100%|██████████| 12/12 [00:35<00:00,  2.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Acc: 0.7227, Val Acc: 0.7713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 Training: 100%|██████████| 47/47 [02:15<00:00,  2.88s/it]\n",
      "Epoch 4/10 Validation: 100%|██████████| 12/12 [00:35<00:00,  2.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Acc: 0.7307, Val Acc: 0.7713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 Training: 100%|██████████| 47/47 [02:16<00:00,  2.91s/it]\n",
      "Epoch 5/10 Validation: 100%|██████████| 12/12 [00:35<00:00,  2.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Acc: 0.7520, Val Acc: 0.7128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 Training: 100%|██████████| 47/47 [02:16<00:00,  2.90s/it]\n",
      "Epoch 6/10 Validation: 100%|██████████| 12/12 [00:35<00:00,  2.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Acc: 0.7200, Val Acc: 0.7766\n",
      "Early stopping\n",
      "\n",
      "Evaluating Model:\n",
      "Model Name: Model_lr0.01_dr0.3_bs32_ncl2_nf32_64_fc128\n",
      "Learning Rate: 0.01\n",
      "Dropout Rate: 0.3\n",
      "Batch Size: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 Training: 100%|██████████| 24/24 [02:16<00:00,  5.70s/it]\n",
      "Epoch 1/10 Validation: 100%|██████████| 6/6 [00:35<00:00,  5.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Acc: 0.6347, Val Acc: 0.7713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 Training: 100%|██████████| 24/24 [02:12<00:00,  5.50s/it]\n",
      "Epoch 2/10 Validation: 100%|██████████| 6/6 [00:34<00:00,  5.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Acc: 0.7120, Val Acc: 0.7713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 Training: 100%|██████████| 24/24 [02:13<00:00,  5.54s/it]\n",
      "Epoch 3/10 Validation: 100%|██████████| 6/6 [00:34<00:00,  5.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Acc: 0.7147, Val Acc: 0.7660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 Training: 100%|██████████| 24/24 [02:12<00:00,  5.51s/it]\n",
      "Epoch 4/10 Validation: 100%|██████████| 6/6 [00:34<00:00,  5.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Acc: 0.7213, Val Acc: 0.7819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 Training: 100%|██████████| 24/24 [02:13<00:00,  5.56s/it]\n",
      "Epoch 5/10 Validation: 100%|██████████| 6/6 [00:34<00:00,  5.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Acc: 0.7307, Val Acc: 0.7926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 Training: 100%|██████████| 24/24 [02:13<00:00,  5.55s/it]\n",
      "Epoch 6/10 Validation: 100%|██████████| 6/6 [00:35<00:00,  5.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Acc: 0.7467, Val Acc: 0.7926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 Training: 100%|██████████| 24/24 [02:11<00:00,  5.50s/it]\n",
      "Epoch 7/10 Validation: 100%|██████████| 6/6 [00:34<00:00,  5.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Train Acc: 0.7373, Val Acc: 0.7660\n",
      "Early stopping\n",
      "\n",
      "Evaluating Model:\n",
      "Model Name: Model_lr0.01_dr0.3_bs32_ncl2_nf32_64_fc256\n",
      "Learning Rate: 0.01\n",
      "Dropout Rate: 0.3\n",
      "Batch Size: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 Training: 100%|██████████| 24/24 [02:13<00:00,  5.57s/it]\n",
      "Epoch 1/10 Validation: 100%|██████████| 6/6 [00:34<00:00,  5.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Acc: 0.6613, Val Acc: 0.7606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 Training: 100%|██████████| 24/24 [02:14<00:00,  5.60s/it]\n",
      "Epoch 2/10 Validation: 100%|██████████| 6/6 [00:34<00:00,  5.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Acc: 0.7067, Val Acc: 0.7819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 Training: 100%|██████████| 24/24 [02:12<00:00,  5.50s/it]\n",
      "Epoch 3/10 Validation: 100%|██████████| 6/6 [00:34<00:00,  5.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Acc: 0.7293, Val Acc: 0.7766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 Training: 100%|██████████| 24/24 [02:13<00:00,  5.57s/it]\n",
      "Epoch 4/10 Validation: 100%|██████████| 6/6 [00:34<00:00,  5.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Acc: 0.7387, Val Acc: 0.7553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 Training: 100%|██████████| 24/24 [02:12<00:00,  5.51s/it]\n",
      "Epoch 5/10 Validation: 100%|██████████| 6/6 [00:34<00:00,  5.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Acc: 0.7053, Val Acc: 0.7766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 Training: 100%|██████████| 24/24 [02:11<00:00,  5.47s/it]\n",
      "Epoch 6/10 Validation: 100%|██████████| 6/6 [00:35<00:00,  5.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Acc: 0.7093, Val Acc: 0.7128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 Training: 100%|██████████| 24/24 [02:12<00:00,  5.52s/it]\n",
      "Epoch 7/10 Validation: 100%|██████████| 6/6 [00:34<00:00,  5.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Train Acc: 0.7053, Val Acc: 0.6330\n",
      "Early stopping\n",
      "\n",
      "Evaluating Model:\n",
      "Model Name: Model_lr0.01_dr0.3_bs32_ncl2_nf64_128_fc128\n",
      "Learning Rate: 0.01\n",
      "Dropout Rate: 0.3\n",
      "Batch Size: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 Training: 100%|██████████| 24/24 [02:13<00:00,  5.58s/it]\n",
      "Epoch 1/10 Validation: 100%|██████████| 6/6 [00:34<00:00,  5.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Acc: 0.6720, Val Acc: 0.7660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 Training: 100%|██████████| 24/24 [02:13<00:00,  5.57s/it]\n",
      "Epoch 2/10 Validation: 100%|██████████| 6/6 [00:35<00:00,  5.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Acc: 0.6933, Val Acc: 0.7447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 Training: 100%|██████████| 24/24 [02:14<00:00,  5.60s/it]\n",
      "Epoch 3/10 Validation: 100%|██████████| 6/6 [00:34<00:00,  5.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Acc: 0.7467, Val Acc: 0.7819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 Training: 100%|██████████| 24/24 [02:14<00:00,  5.59s/it]\n",
      "Epoch 4/10 Validation: 100%|██████████| 6/6 [00:35<00:00,  5.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Acc: 0.7480, Val Acc: 0.7340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 Training: 100%|██████████| 24/24 [02:13<00:00,  5.56s/it]\n",
      "Epoch 5/10 Validation: 100%|██████████| 6/6 [00:35<00:00,  5.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Acc: 0.7307, Val Acc: 0.7447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 Training: 100%|██████████| 24/24 [02:12<00:00,  5.52s/it]\n",
      "Epoch 6/10 Validation: 100%|██████████| 6/6 [00:34<00:00,  5.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Acc: 0.7560, Val Acc: 0.7500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 Training: 100%|██████████| 24/24 [02:13<00:00,  5.58s/it]\n",
      "Epoch 7/10 Validation: 100%|██████████| 6/6 [00:34<00:00,  5.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Train Acc: 0.7173, Val Acc: 0.7021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 Training: 100%|██████████| 24/24 [02:11<00:00,  5.47s/it]\n",
      "Epoch 8/10 Validation: 100%|██████████| 6/6 [00:34<00:00,  5.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Train Acc: 0.7520, Val Acc: 0.7872\n",
      "Early stopping\n",
      "\n",
      "Evaluating Model:\n",
      "Model Name: Model_lr0.01_dr0.3_bs32_ncl2_nf64_128_fc256\n",
      "Learning Rate: 0.01\n",
      "Dropout Rate: 0.3\n",
      "Batch Size: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 Training: 100%|██████████| 24/24 [02:13<00:00,  5.57s/it]\n",
      "Epoch 1/10 Validation: 100%|██████████| 6/6 [00:35<00:00,  5.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Acc: 0.6333, Val Acc: 0.7128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 Training: 100%|██████████| 24/24 [02:15<00:00,  5.63s/it]\n",
      "Epoch 2/10 Validation: 100%|██████████| 6/6 [00:35<00:00,  5.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Acc: 0.7133, Val Acc: 0.7500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 Training: 100%|██████████| 24/24 [02:16<00:00,  5.67s/it]\n",
      "Epoch 3/10 Validation: 100%|██████████| 6/6 [00:35<00:00,  5.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Acc: 0.7253, Val Acc: 0.7606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 Training: 100%|██████████| 24/24 [02:13<00:00,  5.55s/it]\n",
      "Epoch 4/10 Validation: 100%|██████████| 6/6 [00:35<00:00,  5.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Acc: 0.7373, Val Acc: 0.7606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 Training: 100%|██████████| 24/24 [02:13<00:00,  5.55s/it]\n",
      "Epoch 5/10 Validation: 100%|██████████| 6/6 [00:35<00:00,  5.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Acc: 0.7347, Val Acc: 0.7394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 Training: 100%|██████████| 24/24 [02:14<00:00,  5.62s/it]\n",
      "Epoch 6/10 Validation: 100%|██████████| 6/6 [00:35<00:00,  5.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Acc: 0.7173, Val Acc: 0.7287\n",
      "Early stopping\n",
      "\n",
      "Evaluating Model:\n",
      "Model Name: Model_lr0.01_dr0.5_bs16_ncl2_nf32_64_fc128\n",
      "Learning Rate: 0.01\n",
      "Dropout Rate: 0.5\n",
      "Batch Size: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 Training: 100%|██████████| 47/47 [02:14<00:00,  2.86s/it]\n",
      "Epoch 1/10 Validation: 100%|██████████| 12/12 [00:35<00:00,  2.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Acc: 0.6427, Val Acc: 0.7340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 Training: 100%|██████████| 47/47 [02:13<00:00,  2.85s/it]\n",
      "Epoch 2/10 Validation: 100%|██████████| 12/12 [00:35<00:00,  2.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Acc: 0.6800, Val Acc: 0.7819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 Training: 100%|██████████| 47/47 [02:13<00:00,  2.84s/it]\n",
      "Epoch 3/10 Validation: 100%|██████████| 12/12 [00:35<00:00,  2.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Acc: 0.7053, Val Acc: 0.7660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 Training: 100%|██████████| 47/47 [02:14<00:00,  2.86s/it]\n",
      "Epoch 4/10 Validation: 100%|██████████| 12/12 [00:35<00:00,  2.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Acc: 0.7027, Val Acc: 0.6649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 Training: 100%|██████████| 47/47 [02:15<00:00,  2.88s/it]\n",
      "Epoch 5/10 Validation: 100%|██████████| 12/12 [00:35<00:00,  2.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Acc: 0.7253, Val Acc: 0.7872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 Training: 100%|██████████| 47/47 [02:15<00:00,  2.88s/it]\n",
      "Epoch 6/10 Validation: 100%|██████████| 12/12 [00:35<00:00,  2.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Acc: 0.7227, Val Acc: 0.7819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 Training: 100%|██████████| 47/47 [02:14<00:00,  2.86s/it]\n",
      "Epoch 7/10 Validation: 100%|██████████| 12/12 [00:35<00:00,  2.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Train Acc: 0.7293, Val Acc: 0.7766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 Training: 100%|██████████| 47/47 [02:10<00:00,  2.78s/it]\n",
      "Epoch 8/10 Validation: 100%|██████████| 12/12 [00:35<00:00,  2.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Train Acc: 0.7347, Val Acc: 0.7713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 Training: 100%|██████████| 47/47 [02:15<00:00,  2.88s/it]\n",
      "Epoch 9/10 Validation: 100%|██████████| 12/12 [00:35<00:00,  2.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Train Acc: 0.7347, Val Acc: 0.7500\n",
      "Early stopping\n",
      "\n",
      "Evaluating Model:\n",
      "Model Name: Model_lr0.01_dr0.5_bs16_ncl2_nf32_64_fc256\n",
      "Learning Rate: 0.01\n",
      "Dropout Rate: 0.5\n",
      "Batch Size: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 Training: 100%|██████████| 47/47 [02:13<00:00,  2.83s/it]\n",
      "Epoch 1/10 Validation: 100%|██████████| 12/12 [00:35<00:00,  2.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Acc: 0.6507, Val Acc: 0.6170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 Training: 100%|██████████| 47/47 [02:14<00:00,  2.86s/it]\n",
      "Epoch 2/10 Validation: 100%|██████████| 12/12 [00:35<00:00,  2.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Acc: 0.6680, Val Acc: 0.7234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 Training: 100%|██████████| 47/47 [02:15<00:00,  2.89s/it]\n",
      "Epoch 3/10 Validation: 100%|██████████| 12/12 [00:35<00:00,  2.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Acc: 0.6947, Val Acc: 0.7713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 Training: 100%|██████████| 47/47 [02:15<00:00,  2.88s/it]\n",
      "Epoch 4/10 Validation: 100%|██████████| 12/12 [00:35<00:00,  2.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Acc: 0.6880, Val Acc: 0.7447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 Training: 100%|██████████| 47/47 [02:14<00:00,  2.87s/it]\n",
      "Epoch 5/10 Validation: 100%|██████████| 12/12 [00:35<00:00,  2.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Acc: 0.7213, Val Acc: 0.7128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 Training: 100%|██████████| 47/47 [02:13<00:00,  2.84s/it]\n",
      "Epoch 6/10 Validation: 100%|██████████| 12/12 [00:35<00:00,  2.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Acc: 0.7133, Val Acc: 0.7766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 Training: 100%|██████████| 47/47 [02:14<00:00,  2.87s/it]\n",
      "Epoch 7/10 Validation: 100%|██████████| 12/12 [00:35<00:00,  2.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Train Acc: 0.6987, Val Acc: 0.7606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 Training: 100%|██████████| 47/47 [02:15<00:00,  2.89s/it]\n",
      "Epoch 8/10 Validation: 100%|██████████| 12/12 [00:35<00:00,  2.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Train Acc: 0.7200, Val Acc: 0.7553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 Training: 100%|██████████| 47/47 [02:13<00:00,  2.84s/it]\n",
      "Epoch 9/10 Validation: 100%|██████████| 12/12 [00:35<00:00,  2.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Train Acc: 0.7093, Val Acc: 0.7660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 Training: 100%|██████████| 47/47 [02:15<00:00,  2.89s/it]\n",
      "Epoch 10/10 Validation: 100%|██████████| 12/12 [00:35<00:00,  2.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Acc: 0.6813, Val Acc: 0.7394\n",
      "\n",
      "Evaluating Model:\n",
      "Model Name: Model_lr0.01_dr0.5_bs16_ncl2_nf64_128_fc128\n",
      "Learning Rate: 0.01\n",
      "Dropout Rate: 0.5\n",
      "Batch Size: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 Training: 100%|██████████| 47/47 [02:14<00:00,  2.87s/it]\n",
      "Epoch 1/10 Validation: 100%|██████████| 12/12 [00:35<00:00,  2.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Acc: 0.6413, Val Acc: 0.7128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 Training: 100%|██████████| 47/47 [02:14<00:00,  2.87s/it]\n",
      "Epoch 2/10 Validation: 100%|██████████| 12/12 [00:35<00:00,  2.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Acc: 0.6773, Val Acc: 0.7500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 Training: 100%|██████████| 47/47 [02:13<00:00,  2.84s/it]\n",
      "Epoch 3/10 Validation: 100%|██████████| 12/12 [00:35<00:00,  2.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Acc: 0.6893, Val Acc: 0.8032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 Training: 100%|██████████| 47/47 [02:12<00:00,  2.82s/it]\n",
      "Epoch 4/10 Validation: 100%|██████████| 12/12 [00:35<00:00,  2.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Acc: 0.7160, Val Acc: 0.7394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 Training: 100%|██████████| 47/47 [02:15<00:00,  2.89s/it]\n",
      "Epoch 5/10 Validation: 100%|██████████| 12/12 [00:35<00:00,  2.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Acc: 0.6507, Val Acc: 0.6809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 Training: 100%|██████████| 47/47 [02:16<00:00,  2.90s/it]\n",
      "Epoch 6/10 Validation: 100%|██████████| 12/12 [00:35<00:00,  2.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Acc: 0.7200, Val Acc: 0.6170\n",
      "Early stopping\n",
      "\n",
      "Evaluating Model:\n",
      "Model Name: Model_lr0.01_dr0.5_bs16_ncl2_nf64_128_fc256\n",
      "Learning Rate: 0.01\n",
      "Dropout Rate: 0.5\n",
      "Batch Size: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 Training: 100%|██████████| 47/47 [02:16<00:00,  2.90s/it]\n",
      "Epoch 1/10 Validation: 100%|██████████| 12/12 [00:35<00:00,  2.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Acc: 0.6560, Val Acc: 0.6330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 Training: 100%|██████████| 47/47 [02:15<00:00,  2.89s/it]\n",
      "Epoch 2/10 Validation: 100%|██████████| 12/12 [00:35<00:00,  2.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Acc: 0.6600, Val Acc: 0.7500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 Training: 100%|██████████| 47/47 [02:17<00:00,  2.92s/it]\n",
      "Epoch 3/10 Validation: 100%|██████████| 12/12 [00:35<00:00,  2.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Acc: 0.6867, Val Acc: 0.7553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 Training: 100%|██████████| 47/47 [02:13<00:00,  2.85s/it]\n",
      "Epoch 4/10 Validation: 100%|██████████| 12/12 [00:35<00:00,  2.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Acc: 0.6973, Val Acc: 0.7819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 Training: 100%|██████████| 47/47 [02:14<00:00,  2.87s/it]\n",
      "Epoch 5/10 Validation: 100%|██████████| 12/12 [00:35<00:00,  2.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Acc: 0.7200, Val Acc: 0.7766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 Training: 100%|██████████| 47/47 [02:17<00:00,  2.93s/it]\n",
      "Epoch 6/10 Validation: 100%|██████████| 12/12 [00:35<00:00,  2.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Acc: 0.6893, Val Acc: 0.7872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 Training: 100%|██████████| 47/47 [02:16<00:00,  2.91s/it]\n",
      "Epoch 7/10 Validation: 100%|██████████| 12/12 [00:35<00:00,  2.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Train Acc: 0.7000, Val Acc: 0.7181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 Training: 100%|██████████| 47/47 [02:17<00:00,  2.93s/it]\n",
      "Epoch 8/10 Validation: 100%|██████████| 12/12 [00:36<00:00,  3.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Train Acc: 0.7000, Val Acc: 0.7819\n",
      "Early stopping\n",
      "\n",
      "Evaluating Model:\n",
      "Model Name: Model_lr0.01_dr0.5_bs32_ncl2_nf32_64_fc128\n",
      "Learning Rate: 0.01\n",
      "Dropout Rate: 0.5\n",
      "Batch Size: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 Training: 100%|██████████| 24/24 [02:20<00:00,  5.87s/it]\n",
      "Epoch 1/10 Validation: 100%|██████████| 6/6 [00:35<00:00,  5.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Acc: 0.6307, Val Acc: 0.6968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 Training: 100%|██████████| 24/24 [02:16<00:00,  5.67s/it]\n",
      "Epoch 2/10 Validation: 100%|██████████| 6/6 [00:35<00:00,  5.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Acc: 0.7000, Val Acc: 0.7394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 Training: 100%|██████████| 24/24 [02:16<00:00,  5.67s/it]\n",
      "Epoch 3/10 Validation: 100%|██████████| 6/6 [00:35<00:00,  5.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Acc: 0.7040, Val Acc: 0.7766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 Training: 100%|██████████| 24/24 [02:14<00:00,  5.62s/it]\n",
      "Epoch 4/10 Validation: 100%|██████████| 6/6 [00:36<00:00,  6.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Acc: 0.7000, Val Acc: 0.7819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 Training: 100%|██████████| 24/24 [02:19<00:00,  5.83s/it]\n",
      "Epoch 5/10 Validation: 100%|██████████| 6/6 [00:37<00:00,  6.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Acc: 0.7387, Val Acc: 0.6915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 Training: 100%|██████████| 24/24 [02:17<00:00,  5.73s/it]\n",
      "Epoch 6/10 Validation: 100%|██████████| 6/6 [00:36<00:00,  6.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Acc: 0.7067, Val Acc: 0.7979\n",
      "Early stopping\n",
      "\n",
      "Evaluating Model:\n",
      "Model Name: Model_lr0.01_dr0.5_bs32_ncl2_nf32_64_fc256\n",
      "Learning Rate: 0.01\n",
      "Dropout Rate: 0.5\n",
      "Batch Size: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 Training: 100%|██████████| 24/24 [02:17<00:00,  5.73s/it]\n",
      "Epoch 1/10 Validation: 100%|██████████| 6/6 [00:36<00:00,  6.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Acc: 0.6413, Val Acc: 0.5638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 Training: 100%|██████████| 24/24 [02:18<00:00,  5.77s/it]\n",
      "Epoch 2/10 Validation: 100%|██████████| 6/6 [00:36<00:00,  6.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Acc: 0.6987, Val Acc: 0.7553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 Training: 100%|██████████| 24/24 [02:18<00:00,  5.76s/it]\n",
      "Epoch 3/10 Validation: 100%|██████████| 6/6 [00:38<00:00,  6.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Acc: 0.7200, Val Acc: 0.7766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 Training: 100%|██████████| 24/24 [02:20<00:00,  5.85s/it]\n",
      "Epoch 4/10 Validation: 100%|██████████| 6/6 [00:37<00:00,  6.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Acc: 0.7293, Val Acc: 0.7872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 Training:  67%|██████▋   | 16/24 [01:48<00:49,  6.18s/it]"
     ]
    }
   ],
   "source": [
    "# Initialize results list\n",
    "results = []\n",
    "\n",
    "# Hyperparameter tuning loop\n",
    "for architecture in hyperparameter_list:\n",
    "    print(f\"\\nEvaluating Model:\")\n",
    "    print(f\"Model Name: {architecture['name']}\")\n",
    "    print(f\"Learning Rate: {architecture['learning_rate']}\")\n",
    "    print(f\"Dropout Rate: {architecture['dropout_rate']}\")\n",
    "    print(f\"Batch Size: {architecture['batch_size']}\")\n",
    "    # Create datasets and dataloaders\n",
    "    train_dataset = Dataset(train_paths, train_labels, transform=data_transforms['train'])\n",
    "    val_dataset = Dataset(val_paths, val_labels, transform=data_transforms['val'])\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=architecture['batch_size'], shuffle=True, num_workers=4)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=architecture['batch_size'], shuffle=False, num_workers=4)\n",
    "    \n",
    "    # Create model\n",
    "    model = CNNModel(architecture).to(device)\n",
    "    \n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=architecture['learning_rate']) #, decoupled=True)\n",
    "    \n",
    "    # Implement early stopping\n",
    "    best_val_loss = float('inf')\n",
    "    patience = 3\n",
    "    trigger_times = 0\n",
    "    best_model_wts = None\n",
    "    \n",
    "    train_acc_history = []\n",
    "    val_acc_history = []\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        \n",
    "        # Use tqdm for progress bar\n",
    "        for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} Training\"):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Check for NaN loss\n",
    "            if torch.isnan(loss):\n",
    "                print(\"Loss is NaN, skipping batch\")\n",
    "                continue\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_dataset)\n",
    "        epoch_acc = running_corrects.double() / len(train_dataset)\n",
    "        train_acc_history.append(epoch_acc.item())\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_running_loss = 0.0\n",
    "        val_running_corrects = 0\n",
    "        val_labels_list = []\n",
    "        val_preds_list = []\n",
    "        val_probs_list = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} Validation\"):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_running_loss += loss.item() * inputs.size(0)\n",
    "                val_running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "                val_labels_list.extend(labels.cpu().numpy())\n",
    "                val_preds_list.extend(preds.cpu().numpy())\n",
    "                probs = nn.functional.softmax(outputs, dim=1)\n",
    "                val_probs_list.extend(probs[:, 1].cpu().numpy())\n",
    "        \n",
    "        val_epoch_loss = val_running_loss / len(val_dataset)\n",
    "        val_epoch_acc = val_running_corrects.double() / len(val_dataset)\n",
    "        val_acc_history.append(val_epoch_acc.item())\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{NUM_EPOCHS}, Train Acc: {epoch_acc:.4f}, Val Acc: {val_epoch_acc:.4f}\")\n",
    "        \n",
    "        # Early stopping\n",
    "        if val_epoch_loss < best_val_loss:\n",
    "            best_val_loss = val_epoch_loss\n",
    "            best_model_wts = model.state_dict()\n",
    "            trigger_times = 0\n",
    "        else:\n",
    "            trigger_times += 1\n",
    "            if trigger_times >= patience:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "    \n",
    "    # Load best model weights\n",
    "    if best_model_wts:\n",
    "        model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    # Evaluation\n",
    "    y_true = np.array(val_labels_list)\n",
    "    y_pred = np.array(val_preds_list)\n",
    "    val_probs_list = np.array(val_probs_list)\n",
    "    \n",
    "    # Handle NaN values in probabilities\n",
    "    if np.isnan(val_probs_list).any():\n",
    "        print(\"NaN values found in validation probabilities, skipping this model.\")\n",
    "        continue\n",
    "    \n",
    "    # Metrics\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average='binary', zero_division=0)\n",
    "    # For ROC AUC, we need probabilities\n",
    "    try:\n",
    "        roc_auc = roc_auc_score(y_true, val_probs_list)\n",
    "    except ValueError as e:\n",
    "        print(f\"ROC AUC Error: {e}, setting roc_auc to 0.0\")\n",
    "        roc_auc = 0.0\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    sensitivity = recall  # Same as recall\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
    "    \n",
    "    # Store results\n",
    "    results.append({\n",
    "        'name': architecture['name'],\n",
    "        'architecture': architecture,\n",
    "        'val_accuracy': val_epoch_acc.item(),\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1_score,\n",
    "        'roc_auc': roc_auc,\n",
    "        'tp': tp,\n",
    "        'fp': fp,\n",
    "        'tn': tn,\n",
    "        'fn': fn,\n",
    "        'sensitivity': sensitivity,\n",
    "        'specificity': specificity,\n",
    "        'train_acc_history': train_acc_history,\n",
    "        'val_acc_history': val_acc_history\n",
    "    })\n",
    "    \n",
    "    # Free up memory\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Create a DataFrame with the results\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the table with all architectures and their metrics\n",
    "print(\"\\nResults Summary:\")\n",
    "print(results_df[['name', 'val_accuracy', 'precision', 'recall', 'f1_score', 'roc_auc', 'sensitivity', 'specificity']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best performing model based on validation accuracy\n",
    "best_model_idx = results_df['val_accuracy'].idxmax()\n",
    "best_model_info = results_df.loc[best_model_idx]\n",
    "print(\"\\nBest Performing Model:\")\n",
    "print(best_model_info['name'])\n",
    "print(best_model_info['architecture'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified K-Fold Cross Validation\n",
    "skf = StratifiedKFold(n_splits=NUM_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "# Conduct K-Fold validation on the best architecture\n",
    "best_architecture = best_model_info['architecture']\n",
    "print(f\"\\nConducting K-Fold Validation on Best Architecture: {best_architecture['name']}\")\n",
    "\n",
    "fold_metrics = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(image_paths, labels)):\n",
    "    print(f\"Fold {fold+1}/{NUM_FOLDS}\")\n",
    "    # Create datasets and dataloaders\n",
    "    train_paths_fold, val_paths_fold = image_paths[train_idx], image_paths[val_idx]\n",
    "    train_labels_fold, val_labels_fold = labels[train_idx], labels[val_idx]\n",
    "    \n",
    "    train_dataset = Dataset(train_paths_fold, train_labels_fold, transform=data_transforms['train'])\n",
    "    val_dataset = Dataset(val_paths_fold, val_labels_fold, transform=data_transforms['val'])\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=best_architecture['batch_size'], shuffle=True, num_workers=4)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=best_architecture['batch_size'], shuffle=False, num_workers=4)\n",
    "    \n",
    "    # Create model\n",
    "    model = CNNModel(best_architecture).to(device)\n",
    "    \n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=best_architecture['learning_rate'])\n",
    "    \n",
    "    # Implement early stopping\n",
    "    best_val_loss = float('inf')\n",
    "    patience = 3\n",
    "    trigger_times = 0\n",
    "    best_model_wts = None\n",
    "    \n",
    "    train_acc_history = []\n",
    "    val_acc_history = []\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        \n",
    "        # Use tqdm for progress bar\n",
    "        for inputs, labels in tqdm(train_loader, desc=f\"Fold {fold+1} Epoch {epoch+1}/{NUM_EPOCHS} Training\"):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Check for NaN loss\n",
    "            if torch.isnan(loss):\n",
    "                print(\"Loss is NaN, skipping batch\")\n",
    "                continue\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_dataset)\n",
    "        epoch_acc = running_corrects.double() / len(train_dataset)\n",
    "        train_acc_history.append(epoch_acc.item())\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_running_loss = 0.0\n",
    "        val_running_corrects = 0\n",
    "        val_labels_list = []\n",
    "        val_preds_list = []\n",
    "        val_probs_list = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in tqdm(val_loader, desc=f\"Fold {fold+1} Epoch {epoch+1}/{NUM_EPOCHS} Validation\"):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_running_loss += loss.item() * inputs.size(0)\n",
    "                val_running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "                val_labels_list.extend(labels.cpu().numpy())\n",
    "                val_preds_list.extend(preds.cpu().numpy())\n",
    "                probs = nn.functional.softmax(outputs, dim=1)\n",
    "                val_probs_list.extend(probs[:, 1].cpu().numpy())\n",
    "        \n",
    "        val_epoch_loss = val_running_loss / len(val_dataset)\n",
    "        val_epoch_acc = val_running_corrects.double() / len(val_dataset)\n",
    "        val_acc_history.append(val_epoch_acc.item())\n",
    "        \n",
    "        print(f\"Fold {fold+1}, Epoch {epoch+1}/{NUM_EPOCHS}, Train Acc: {epoch_acc:.4f}, Val Acc: {val_epoch_acc:.4f}\")\n",
    "        \n",
    "        # Early stopping\n",
    "        if val_epoch_loss < best_val_loss:\n",
    "            best_val_loss = val_epoch_loss\n",
    "            best_model_wts = model.state_dict()\n",
    "            trigger_times = 0\n",
    "        else:\n",
    "            trigger_times += 1\n",
    "            if trigger_times >= patience:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "    \n",
    "    # Load best model weights\n",
    "    if best_model_wts:\n",
    "        model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    # Evaluation\n",
    "    y_true = np.array(val_labels_list)\n",
    "    y_pred = np.array(val_preds_list)\n",
    "    val_probs_list = np.array(val_probs_list)\n",
    "    \n",
    "    # Handle NaN values in probabilities\n",
    "    if np.isnan(val_probs_list).any():\n",
    "        print(\"NaN values found in validation probabilities, skipping this fold.\")\n",
    "        continue\n",
    "    \n",
    "    # Metrics\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average='binary', zero_division=0)\n",
    "    # For ROC AUC, we need probabilities\n",
    "    try:\n",
    "        roc_auc = roc_auc_score(y_true, val_probs_list)\n",
    "    except ValueError as e:\n",
    "        print(f\"ROC AUC Error: {e}, setting roc_auc to 0.0\")\n",
    "        roc_auc = 0.0\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    sensitivity = recall\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
    "    \n",
    "    fold_metrics.append({\n",
    "        'fold': fold+1,\n",
    "        'val_accuracy': val_epoch_acc.item(),\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1_score,\n",
    "        'roc_auc': roc_auc,\n",
    "        'tp': tp,\n",
    "        'fp': fp,\n",
    "        'tn': tn,\n",
    "        'fn': fn,\n",
    "        'sensitivity': sensitivity,\n",
    "        'specificity': specificity\n",
    "    })\n",
    "    \n",
    "    # Free up memory\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Average metrics over folds\n",
    "kfold_results_df = pd.DataFrame(fold_metrics)\n",
    "avg_metrics = kfold_results_df.mean()\n",
    "print(\"\\nK-Fold Cross-Validation Results:\")\n",
    "print(kfold_results_df)\n",
    "print(\"\\nAverage Metrics over all folds:\")\n",
    "print(avg_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the entire balanced dataset for training\n",
    "final_architecture = best_architecture.copy()\n",
    "train_dataset = Dataset(image_paths, labels, transform=data_transforms['train'])\n",
    "train_loader = DataLoader(train_dataset, batch_size=final_architecture['batch_size'], shuffle=True, num_workers=4)\n",
    "\n",
    "# Create model\n",
    "model = CNNModel(final_architecture).to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=final_architecture['learning_rate'], decoupled=True)\n",
    "\n",
    "# Implement early stopping\n",
    "best_loss = float('inf')\n",
    "patience = 3\n",
    "trigger_times = 0\n",
    "best_model_wts = None\n",
    "\n",
    "train_acc_history = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    \n",
    "    # Use tqdm for progress bar\n",
    "    for inputs, labels in tqdm(train_loader, desc=f\"Final Training Epoch {epoch+1}/{NUM_EPOCHS}\"):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Check for NaN loss\n",
    "        if torch.isnan(loss):\n",
    "            print(\"Loss is NaN, skipping batch\")\n",
    "            continue\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Statistics\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    epoch_acc = running_corrects.double() / len(train_dataset)\n",
    "    train_acc_history.append(epoch_acc.item())\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS}, Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.4f}\")\n",
    "    \n",
    "    # Early stopping\n",
    "    if epoch_loss < best_loss:\n",
    "        best_loss = epoch_loss\n",
    "        best_model_wts = model.state_dict()\n",
    "        trigger_times = 0\n",
    "    else:\n",
    "        trigger_times += 1\n",
    "        if trigger_times >= patience:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "# Load best model weights\n",
    "if best_model_wts:\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "# Save the final model\n",
    "torch.save(model.state_dict(), 'final_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Training Accuracy over Time\n",
    "plt.figure()\n",
    "plt.plot(train_acc_history, label='Training Accuracy')\n",
    "plt.title('Training Accuracy Over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Evaluation\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "all_probs = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in tqdm(train_loader, desc=\"Final Evaluation\"):\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        probs = nn.functional.softmax(outputs, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "        all_probs.extend(probs[:, 1].cpu().numpy())\n",
    "\n",
    "y_true = np.array(all_labels)\n",
    "y_pred = np.array(all_preds)\n",
    "all_probs = np.array(all_probs)\n",
    "\n",
    "# Handle NaN values in probabilities\n",
    "if np.isnan(all_probs).any():\n",
    "    print(\"NaN values found in probabilities, setting ROC AUC to 0.0\")\n",
    "    roc_auc = 0.0\n",
    "else:\n",
    "    roc_auc = roc_auc_score(y_true, all_probs)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure()\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix on Full Dataset')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(NUM_CLASSES)\n",
    "classes = ['Fire', 'No Fire']\n",
    "plt.xticks(tick_marks, classes, rotation=45)\n",
    "plt.yticks(tick_marks, classes)\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Metrics\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average='binary', zero_division=0)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "sensitivity = recall\n",
    "specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
    "\n",
    "print(\"\\nFinal Evaluation Metrics on Full Dataset:\")\n",
    "print(f\"Accuracy: {train_acc_history[-1]:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1_score:.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "print(f\"Sensitivity: {sensitivity:.4f}\")\n",
    "print(f\"Specificity: {specificity:.4f}\")\n",
    "print(f\"TP: {tp}, FP: {fp}, TN: {tn}, FN: {fn}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
